{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "corpus = \"बिहीबार ४ जनाले जिल्ला अदालत मोरङसमक्ष थुनछेक बहस गरेका थिए । थप ३ जनाले शुक्रबार बहस गर्दै उपलब्ध प्रमाणका आधारमा प्रतिवादीहरु कसुरदार देखिएको भन्दै थुनामै राखेर थप अनुसन्धान र कारबाही अघि \"\n",
    "# corpus_raw = corpus.lower() # converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['बिहीबार', '४', 'जनाले', 'जिल्ला', 'अदालत', 'मोरङसमक्ष', 'थुनछेक', 'बहस', 'गरेका', 'थिए', '।', 'थप', '३', 'जनाले', 'शुक्रबार', 'बहस', 'गर्दै', 'उपलब्ध', 'प्रमाणका', 'आधारमा', 'प्रतिवादीहरु', 'कसुरदार', 'देखिएको', 'भन्दै', 'थुनामै', 'राखेर', 'थप', 'अनुसन्धान', 'र', 'कारबाही', 'अघि']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_raw.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'शुक्रबार', 'राखेर', 'प्रतिवादीहरु', 'आधारमा', 'उपलब्ध', 'थिए', 'बिहीबार', 'जिल्ला', 'अघि', 'थुनछेक', 'अनुसन्धान', 'थुनामै', 'अदालत', 'प्रमाणका', 'गरेका', 'जनाले', 'र', 'कसुरदार', '३', 'भन्दै', 'थप', 'मोरङसमक्ष', 'बहस', 'कारबाही', 'देखिएको', '४', 'गर्दै'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning the raw corpus and removing the duplicates\n",
    "words = []\n",
    "for word in corpus_raw.split():\n",
    "    if word != '।': # we dont want to treat . as a word\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words) # remove all the duplicate words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "\n",
    "vocab_size = len(words)\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "    \n",
    "print(word2int['शुक्रबार'])\n",
    "\n",
    "# print(int2word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['बिहीबार', '४', 'जनाले', 'जिल्ला', 'अदालत', 'मोरङसमक्ष', 'थुनछेक', 'बहस', 'गरेका', 'थिए', '।', 'थप', '३', 'जनाले', 'शुक्रबार', 'बहस', 'गर्दै', 'उपलब्ध', 'प्रमाणका', 'आधारमा', 'प्रतिवादीहरु', 'कसुरदार', 'देखिएको', 'भन्दै', 'थुनामै', 'राखेर', 'थप', 'अनुसन्धान', 'र', 'कारबाही', 'अघि']]\n"
     ]
    }
   ],
   "source": [
    "# splitting the sentences into arrays\n",
    "raw_sentences = corpus_raw.split('।')\n",
    "sentences = []\n",
    "\n",
    "for sentence in raw_sentences:\n",
    "    sentences.append(sentence.split())\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the word pair: \n",
      "[['शुक्रबार', 'बिहीबार'], ['शुक्रबार', '४'], ['शुक्रबार', 'जनाले'], ['राखेर', 'बिहीबार'], ['राखेर', '४'], ['राखेर', 'जनाले'], ['राखेर', 'जिल्ला'], ['प्रतिवादीहरु', 'बिहीबार'], ['प्रतिवादीहरु', '४'], ['प्रतिवादीहरु', 'जनाले'], ['प्रतिवादीहरु', 'जिल्ला'], ['प्रतिवादीहरु', 'अदालत'], ['आधारमा', '४'], ['आधारमा', 'जनाले'], ['आधारमा', 'जिल्ला'], ['आधारमा', 'अदालत'], ['आधारमा', 'मोरङसमक्ष'], ['उपलब्ध', 'जनाले'], ['उपलब्ध', 'जिल्ला'], ['उपलब्ध', 'अदालत'], ['उपलब्ध', 'मोरङसमक्ष'], ['उपलब्ध', 'थुनछेक'], ['थिए', 'जिल्ला'], ['थिए', 'अदालत'], ['थिए', 'मोरङसमक्ष'], ['थिए', 'थुनछेक'], ['थिए', 'बहस'], ['बिहीबार', 'अदालत'], ['बिहीबार', 'मोरङसमक्ष'], ['बिहीबार', 'थुनछेक'], ['बिहीबार', 'बहस'], ['बिहीबार', 'गरेका'], ['जिल्ला', 'मोरङसमक्ष'], ['जिल्ला', 'थुनछेक'], ['जिल्ला', 'बहस'], ['जिल्ला', 'गरेका'], ['जिल्ला', 'थिए'], ['अघि', 'थुनछेक'], ['अघि', 'बहस'], ['अघि', 'गरेका'], ['अघि', 'थिए'], ['अघि', '।'], ['थुनछेक', 'बहस'], ['थुनछेक', 'गरेका'], ['थुनछेक', 'थिए'], ['थुनछेक', '।'], ['थुनछेक', 'थप'], ['अनुसन्धान', 'गरेका'], ['अनुसन्धान', 'थिए'], ['अनुसन्धान', '।'], ['अनुसन्धान', 'थप'], ['अनुसन्धान', '३'], ['थुनामै', 'थिए'], ['थुनामै', '।'], ['थुनामै', 'थप'], ['थुनामै', '३'], ['थुनामै', 'जनाले'], ['अदालत', '।'], ['अदालत', 'थप'], ['अदालत', '३'], ['अदालत', 'जनाले'], ['अदालत', 'शुक्रबार'], ['प्रमाणका', 'थप'], ['प्रमाणका', '३'], ['प्रमाणका', 'जनाले'], ['प्रमाणका', 'शुक्रबार'], ['प्रमाणका', 'बहस'], ['गरेका', '३'], ['गरेका', 'जनाले'], ['गरेका', 'शुक्रबार'], ['गरेका', 'बहस'], ['गरेका', 'गर्दै'], ['जनाले', 'शुक्रबार'], ['जनाले', 'बहस'], ['जनाले', 'गर्दै'], ['जनाले', 'उपलब्ध'], ['र', 'शुक्रबार'], ['र', 'बहस'], ['र', 'गर्दै'], ['र', 'उपलब्ध'], ['र', 'प्रमाणका'], ['कसुरदार', 'बहस'], ['कसुरदार', 'गर्दै'], ['कसुरदार', 'उपलब्ध'], ['कसुरदार', 'प्रमाणका'], ['कसुरदार', 'आधारमा'], ['३', 'गर्दै'], ['३', 'उपलब्ध'], ['३', 'प्रमाणका'], ['३', 'आधारमा'], ['३', 'प्रतिवादीहरु'], ['भन्दै', 'उपलब्ध'], ['भन्दै', 'प्रमाणका'], ['भन्दै', 'आधारमा'], ['भन्दै', 'प्रतिवादीहरु'], ['भन्दै', 'कसुरदार'], ['थप', 'प्रमाणका'], ['थप', 'आधारमा'], ['थप', 'प्रतिवादीहरु'], ['थप', 'कसुरदार'], ['थप', 'देखिएको'], ['मोरङसमक्ष', 'आधारमा'], ['मोरङसमक्ष', 'प्रतिवादीहरु'], ['मोरङसमक्ष', 'कसुरदार'], ['मोरङसमक्ष', 'देखिएको'], ['मोरङसमक्ष', 'भन्दै'], ['बहस', 'प्रतिवादीहरु'], ['बहस', 'कसुरदार'], ['बहस', 'देखिएको'], ['बहस', 'भन्दै'], ['बहस', 'थुनामै'], ['कारबाही', 'कसुरदार'], ['कारबाही', 'देखिएको'], ['कारबाही', 'भन्दै'], ['कारबाही', 'थुनामै'], ['कारबाही', 'राखेर'], ['देखिएको', 'भन्दै'], ['देखिएको', 'थुनामै'], ['देखिएको', 'राखेर'], ['देखिएको', 'थप'], ['४', 'भन्दै'], ['४', 'थुनामै'], ['४', 'राखेर'], ['४', 'थप'], ['४', 'अनुसन्धान'], ['गर्दै', 'थुनामै'], ['गर्दै', 'राखेर'], ['गर्दै', 'थप'], ['गर्दै', 'अनुसन्धान'], ['गर्दै', 'र']]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "WINDOW_SIZE = 2\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(words):\n",
    "        for nb_word in sentence[max(word_index- WINDOW_SIZE, 0) : min(word_index+WINDOW_SIZE, len(sentence)) + 1]:\n",
    "            if nb_word != word:\n",
    "                data.append([word, nb_word])\n",
    "print('Generating the word pair: ')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'।'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7ee71ccc3424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mword2int\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mdata_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# convert to one_hot using the index returned from word2int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mword2int\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mdata_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '।'"
     ]
    }
   ],
   "source": [
    "# now convert all to one_hot_vectors\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp\n",
    "\n",
    "x_train = [] # input_word\n",
    "y_train = [] # output_word\n",
    "\n",
    "for data_word in data:\n",
    "    x_train.append(to_one_hot( word2int[ data_word[0] ], vocab_size ) ) # convert to one_hot using the index returned from word2int\n",
    "    y_train.append(to_one_hot( word2int[ data_word[1] ], vocab_size ) )\n",
    "    \n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to numpy array: \n",
      "[[0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print('Converting to numpy array: ')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 7) (34, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make tensorflow placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding networks weight and biases\n",
    "EMBEDDING_DIM = 5\n",
    "\n",
    "w1 = tf.Variable( tf.random_normal([vocab_size, EMBEDDING_DIM]) ) #weight\n",
    "b1 = tf.Variable( tf.random_normal([EMBEDDING_DIM]) ) #bias\n",
    "\n",
    "hidden_representation = tf.add( tf.matmul(x, w1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable( tf.random_normal([EMBEDDING_DIM, vocab_size]) )\n",
    "b2 = tf.Variable( tf.random_normal( [vocab_size] ))\n",
    "\n",
    "prediction = tf.nn.softmax( tf.add( tf.matmul(hidden_representation, w2), b2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we train the neural network\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]) )\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  5.7345777\n",
      "loss is:  5.0509543\n",
      "loss is:  4.545597\n",
      "loss is:  4.170566\n",
      "loss is:  3.879713\n",
      "loss is:  3.6407878\n",
      "loss is:  3.437089\n",
      "loss is:  3.261154\n",
      "loss is:  3.1091557\n",
      "loss is:  2.9782014\n",
      "loss is:  2.8654358\n",
      "loss is:  2.7679555\n",
      "loss is:  2.6830075\n",
      "loss is:  2.6081781\n",
      "loss is:  2.5414877\n",
      "loss is:  2.481382\n",
      "loss is:  2.4266763\n",
      "loss is:  2.376478\n",
      "loss is:  2.330114\n",
      "loss is:  2.2870743\n",
      "loss is:  2.2469664\n",
      "loss is:  2.2094822\n",
      "loss is:  2.1743777\n",
      "loss is:  2.1414545\n",
      "loss is:  2.1105473\n",
      "loss is:  2.0815191\n",
      "loss is:  2.0542505\n",
      "loss is:  2.0286362\n",
      "loss is:  2.0045817\n",
      "loss is:  1.981998\n",
      "loss is:  1.9608012\n",
      "loss is:  1.9409093\n",
      "loss is:  1.9222423\n",
      "loss is:  1.9047214\n",
      "loss is:  1.88827\n",
      "loss is:  1.8728119\n",
      "loss is:  1.8582753\n",
      "loss is:  1.84459\n",
      "loss is:  1.8316905\n",
      "loss is:  1.8195148\n",
      "loss is:  1.8080053\n",
      "loss is:  1.7971095\n",
      "loss is:  1.7867782\n",
      "loss is:  1.7769674\n",
      "loss is:  1.7676368\n",
      "loss is:  1.7587494\n",
      "loss is:  1.7502724\n",
      "loss is:  1.7421753\n",
      "loss is:  1.7344314\n",
      "loss is:  1.727016\n",
      "loss is:  1.7199063\n",
      "loss is:  1.7130827\n",
      "loss is:  1.7065262\n",
      "loss is:  1.70022\n",
      "loss is:  1.694149\n",
      "loss is:  1.6882992\n",
      "loss is:  1.6826574\n",
      "loss is:  1.6772121\n",
      "loss is:  1.6719522\n",
      "loss is:  1.6668679\n",
      "loss is:  1.66195\n",
      "loss is:  1.6571895\n",
      "loss is:  1.6525792\n",
      "loss is:  1.6481109\n",
      "loss is:  1.6437787\n",
      "loss is:  1.6395752\n",
      "loss is:  1.6354954\n",
      "loss is:  1.6315335\n",
      "loss is:  1.627684\n",
      "loss is:  1.6239424\n",
      "loss is:  1.6203035\n",
      "loss is:  1.6167638\n",
      "loss is:  1.6133189\n",
      "loss is:  1.6099648\n",
      "loss is:  1.6066985\n",
      "loss is:  1.6035161\n",
      "loss is:  1.6004145\n",
      "loss is:  1.5973905\n",
      "loss is:  1.5944418\n",
      "loss is:  1.5915651\n",
      "loss is:  1.5887581\n",
      "loss is:  1.5860184\n",
      "loss is:  1.5833433\n",
      "loss is:  1.5807308\n",
      "loss is:  1.5781788\n",
      "loss is:  1.575685\n",
      "loss is:  1.573248\n",
      "loss is:  1.5708655\n",
      "loss is:  1.5685358\n",
      "loss is:  1.5662571\n",
      "loss is:  1.5640283\n",
      "loss is:  1.561847\n",
      "loss is:  1.5597125\n",
      "loss is:  1.557623\n",
      "loss is:  1.555577\n",
      "loss is:  1.5535734\n",
      "loss is:  1.551611\n",
      "loss is:  1.5496882\n",
      "loss is:  1.5478041\n",
      "loss is:  1.5459576\n",
      "loss is:  1.5441473\n",
      "loss is:  1.5423723\n",
      "loss is:  1.5406319\n",
      "loss is:  1.5389246\n",
      "loss is:  1.5372498\n",
      "loss is:  1.5356065\n",
      "loss is:  1.5339938\n",
      "loss is:  1.5324106\n",
      "loss is:  1.5308564\n",
      "loss is:  1.5293303\n",
      "loss is:  1.5278317\n",
      "loss is:  1.5263594\n",
      "loss is:  1.5249128\n",
      "loss is:  1.5234917\n",
      "loss is:  1.522095\n",
      "loss is:  1.5207217\n",
      "loss is:  1.5193719\n",
      "loss is:  1.5180445\n",
      "loss is:  1.516739\n",
      "loss is:  1.5154546\n",
      "loss is:  1.5141913\n",
      "loss is:  1.512948\n",
      "loss is:  1.5117245\n",
      "loss is:  1.51052\n",
      "loss is:  1.5093341\n",
      "loss is:  1.5081666\n",
      "loss is:  1.5070167\n",
      "loss is:  1.505884\n",
      "loss is:  1.504768\n",
      "loss is:  1.5036685\n",
      "loss is:  1.5025848\n",
      "loss is:  1.5015167\n",
      "loss is:  1.5004636\n",
      "loss is:  1.4994253\n",
      "loss is:  1.4984014\n",
      "loss is:  1.4973913\n",
      "loss is:  1.4963951\n",
      "loss is:  1.495412\n",
      "loss is:  1.494442\n",
      "loss is:  1.4934846\n",
      "loss is:  1.4925394\n",
      "loss is:  1.4916061\n",
      "loss is:  1.4906849\n",
      "loss is:  1.4897748\n",
      "loss is:  1.4888759\n",
      "loss is:  1.4879879\n",
      "loss is:  1.4871106\n",
      "loss is:  1.4862434\n",
      "loss is:  1.4853865\n",
      "loss is:  1.4845395\n",
      "loss is:  1.4837017\n",
      "loss is:  1.4828736\n",
      "loss is:  1.4820546\n",
      "loss is:  1.4812444\n",
      "loss is:  1.480443\n",
      "loss is:  1.4796501\n",
      "loss is:  1.4788656\n",
      "loss is:  1.4780893\n",
      "loss is:  1.4773207\n",
      "loss is:  1.4765599\n",
      "loss is:  1.4758068\n",
      "loss is:  1.4750609\n",
      "loss is:  1.4743224\n",
      "loss is:  1.473591\n",
      "loss is:  1.4728664\n",
      "loss is:  1.4721484\n",
      "loss is:  1.4714373\n",
      "loss is:  1.4707325\n",
      "loss is:  1.4700339\n",
      "loss is:  1.4693415\n",
      "loss is:  1.4686552\n",
      "loss is:  1.4679747\n",
      "loss is:  1.4673002\n",
      "loss is:  1.466631\n",
      "loss is:  1.4659677\n",
      "loss is:  1.4653095\n",
      "loss is:  1.4646568\n",
      "loss is:  1.4640093\n",
      "loss is:  1.4633667\n",
      "loss is:  1.4627295\n",
      "loss is:  1.4620967\n",
      "loss is:  1.4614688\n",
      "loss is:  1.4608457\n",
      "loss is:  1.460227\n",
      "loss is:  1.4596131\n",
      "loss is:  1.4590034\n",
      "loss is:  1.4583981\n",
      "loss is:  1.457797\n",
      "loss is:  1.4572\n",
      "loss is:  1.4566071\n",
      "loss is:  1.4560184\n",
      "loss is:  1.4554337\n",
      "loss is:  1.4548525\n",
      "loss is:  1.4542754\n",
      "loss is:  1.4537019\n",
      "loss is:  1.4531319\n",
      "loss is:  1.4525656\n",
      "loss is:  1.4520029\n",
      "loss is:  1.4514436\n",
      "loss is:  1.4508879\n",
      "loss is:  1.4503354\n",
      "loss is:  1.4497862\n",
      "loss is:  1.4492402\n",
      "loss is:  1.4486973\n",
      "loss is:  1.4481577\n",
      "loss is:  1.4476213\n",
      "loss is:  1.4470875\n",
      "loss is:  1.446557\n",
      "loss is:  1.4460295\n",
      "loss is:  1.4455049\n",
      "loss is:  1.444983\n",
      "loss is:  1.4444642\n",
      "loss is:  1.4439478\n",
      "loss is:  1.4434342\n",
      "loss is:  1.4429235\n",
      "loss is:  1.4424152\n",
      "loss is:  1.4419099\n",
      "loss is:  1.4414068\n",
      "loss is:  1.4409065\n",
      "loss is:  1.4404086\n",
      "loss is:  1.4399132\n",
      "loss is:  1.4394201\n",
      "loss is:  1.4389296\n",
      "loss is:  1.4384414\n",
      "loss is:  1.4379556\n",
      "loss is:  1.4374721\n",
      "loss is:  1.436991\n",
      "loss is:  1.4365121\n",
      "loss is:  1.4360355\n",
      "loss is:  1.4355611\n",
      "loss is:  1.4350888\n",
      "loss is:  1.4346187\n",
      "loss is:  1.4341507\n",
      "loss is:  1.4336851\n",
      "loss is:  1.4332212\n",
      "loss is:  1.4327595\n",
      "loss is:  1.4323\n",
      "loss is:  1.4318424\n",
      "loss is:  1.431387\n",
      "loss is:  1.4309335\n",
      "loss is:  1.4304819\n",
      "loss is:  1.4300321\n",
      "loss is:  1.4295846\n",
      "loss is:  1.429139\n",
      "loss is:  1.4286951\n",
      "loss is:  1.4282532\n",
      "loss is:  1.4278132\n",
      "loss is:  1.4273748\n",
      "loss is:  1.4269384\n",
      "loss is:  1.4265039\n",
      "loss is:  1.4260713\n",
      "loss is:  1.4256402\n",
      "loss is:  1.4252111\n",
      "loss is:  1.4247837\n",
      "loss is:  1.424358\n",
      "loss is:  1.4239341\n",
      "loss is:  1.423512\n",
      "loss is:  1.4230914\n",
      "loss is:  1.4226727\n",
      "loss is:  1.4222555\n",
      "loss is:  1.4218402\n",
      "loss is:  1.4214265\n",
      "loss is:  1.4210144\n",
      "loss is:  1.420604\n",
      "loss is:  1.4201953\n",
      "loss is:  1.4197882\n",
      "loss is:  1.4193826\n",
      "loss is:  1.4189787\n",
      "loss is:  1.4185764\n",
      "loss is:  1.4181757\n",
      "loss is:  1.4177766\n",
      "loss is:  1.4173789\n",
      "loss is:  1.4169829\n",
      "loss is:  1.4165885\n",
      "loss is:  1.4161956\n",
      "loss is:  1.4158043\n",
      "loss is:  1.4154143\n",
      "loss is:  1.4150261\n",
      "loss is:  1.4146392\n",
      "loss is:  1.4142541\n",
      "loss is:  1.4138703\n",
      "loss is:  1.4134879\n",
      "loss is:  1.4131072\n",
      "loss is:  1.412728\n",
      "loss is:  1.4123499\n",
      "loss is:  1.4119737\n",
      "loss is:  1.4115988\n",
      "loss is:  1.4112253\n",
      "loss is:  1.4108534\n",
      "loss is:  1.410483\n",
      "loss is:  1.4101137\n",
      "loss is:  1.409746\n",
      "loss is:  1.4093798\n",
      "loss is:  1.409015\n",
      "loss is:  1.4086518\n",
      "loss is:  1.4082899\n",
      "loss is:  1.4079292\n",
      "loss is:  1.40757\n",
      "loss is:  1.4072124\n",
      "loss is:  1.4068561\n",
      "loss is:  1.406501\n",
      "loss is:  1.4061476\n",
      "loss is:  1.4057953\n",
      "loss is:  1.4054445\n",
      "loss is:  1.4050951\n",
      "loss is:  1.404747\n",
      "loss is:  1.4044005\n",
      "loss is:  1.4040552\n",
      "loss is:  1.4037111\n",
      "loss is:  1.4033686\n",
      "loss is:  1.4030273\n",
      "loss is:  1.4026875\n",
      "loss is:  1.4023489\n",
      "loss is:  1.4020118\n",
      "loss is:  1.4016758\n",
      "loss is:  1.4013413\n",
      "loss is:  1.4010081\n",
      "loss is:  1.4006761\n",
      "loss is:  1.4003457\n",
      "loss is:  1.4000164\n",
      "loss is:  1.3996884\n",
      "loss is:  1.399362\n",
      "loss is:  1.3990366\n",
      "loss is:  1.3987128\n",
      "loss is:  1.3983902\n",
      "loss is:  1.3980685\n",
      "loss is:  1.3977486\n",
      "loss is:  1.3974298\n",
      "loss is:  1.3971124\n",
      "loss is:  1.3967961\n",
      "loss is:  1.3964812\n",
      "loss is:  1.3961675\n",
      "loss is:  1.3958553\n",
      "loss is:  1.3955442\n",
      "loss is:  1.3952345\n",
      "loss is:  1.3949257\n",
      "loss is:  1.3946185\n",
      "loss is:  1.3943127\n",
      "loss is:  1.3940078\n",
      "loss is:  1.3937044\n",
      "loss is:  1.3934022\n",
      "loss is:  1.3931012\n",
      "loss is:  1.3928016\n",
      "loss is:  1.392503\n",
      "loss is:  1.392206\n",
      "loss is:  1.39191\n",
      "loss is:  1.3916152\n",
      "loss is:  1.3913219\n",
      "loss is:  1.3910296\n",
      "loss is:  1.3907385\n",
      "loss is:  1.3904486\n",
      "loss is:  1.3901601\n",
      "loss is:  1.3898727\n",
      "loss is:  1.3895867\n",
      "loss is:  1.3893018\n",
      "loss is:  1.389018\n",
      "loss is:  1.3887357\n",
      "loss is:  1.3884543\n",
      "loss is:  1.3881743\n",
      "loss is:  1.3878953\n",
      "loss is:  1.3876176\n",
      "loss is:  1.3873413\n",
      "loss is:  1.387066\n",
      "loss is:  1.3867921\n",
      "loss is:  1.386519\n",
      "loss is:  1.3862473\n",
      "loss is:  1.3859769\n",
      "loss is:  1.3857076\n",
      "loss is:  1.3854393\n",
      "loss is:  1.3851725\n",
      "loss is:  1.3849065\n",
      "loss is:  1.384642\n",
      "loss is:  1.3843784\n",
      "loss is:  1.3841162\n",
      "loss is:  1.383855\n",
      "loss is:  1.383595\n",
      "loss is:  1.3833362\n",
      "loss is:  1.3830785\n",
      "loss is:  1.3828219\n",
      "loss is:  1.3825666\n",
      "loss is:  1.3823122\n",
      "loss is:  1.3820593\n",
      "loss is:  1.3818071\n",
      "loss is:  1.3815565\n",
      "loss is:  1.3813066\n",
      "loss is:  1.3810581\n",
      "loss is:  1.3808107\n",
      "loss is:  1.3805645\n",
      "loss is:  1.3803189\n",
      "loss is:  1.3800749\n",
      "loss is:  1.3798318\n",
      "loss is:  1.37959\n",
      "loss is:  1.3793494\n",
      "loss is:  1.3791094\n",
      "loss is:  1.3788708\n",
      "loss is:  1.3786334\n",
      "loss is:  1.378397\n",
      "loss is:  1.3781615\n",
      "loss is:  1.3779274\n",
      "loss is:  1.3776942\n",
      "loss is:  1.3774623\n",
      "loss is:  1.3772312\n",
      "loss is:  1.3770013\n",
      "loss is:  1.3767724\n",
      "loss is:  1.3765446\n",
      "loss is:  1.3763177\n",
      "loss is:  1.3760921\n",
      "loss is:  1.3758676\n",
      "loss is:  1.3756438\n",
      "loss is:  1.3754214\n",
      "loss is:  1.3751999\n",
      "loss is:  1.3749796\n",
      "loss is:  1.3747602\n",
      "loss is:  1.3745418\n",
      "loss is:  1.3743243\n",
      "loss is:  1.3741082\n",
      "loss is:  1.3738928\n",
      "loss is:  1.3736787\n",
      "loss is:  1.3734653\n",
      "loss is:  1.3732531\n",
      "loss is:  1.3730419\n",
      "loss is:  1.3728317\n",
      "loss is:  1.3726224\n",
      "loss is:  1.3724141\n",
      "loss is:  1.3722068\n",
      "loss is:  1.3720007\n",
      "loss is:  1.3717954\n",
      "loss is:  1.371591\n",
      "loss is:  1.3713877\n",
      "loss is:  1.3711854\n",
      "loss is:  1.3709841\n",
      "loss is:  1.3707838\n",
      "loss is:  1.3705844\n",
      "loss is:  1.3703858\n",
      "loss is:  1.3701885\n",
      "loss is:  1.3699918\n",
      "loss is:  1.3697963\n",
      "loss is:  1.3696016\n",
      "loss is:  1.369408\n",
      "loss is:  1.3692151\n",
      "loss is:  1.3690233\n",
      "loss is:  1.3688326\n",
      "loss is:  1.3686424\n",
      "loss is:  1.3684535\n",
      "loss is:  1.3682654\n",
      "loss is:  1.3680781\n",
      "loss is:  1.3678919\n",
      "loss is:  1.3677067\n",
      "loss is:  1.3675221\n",
      "loss is:  1.3673385\n",
      "loss is:  1.3671559\n",
      "loss is:  1.3669741\n",
      "loss is:  1.3667933\n",
      "loss is:  1.3666131\n",
      "loss is:  1.3664341\n",
      "loss is:  1.3662559\n",
      "loss is:  1.3660785\n",
      "loss is:  1.3659021\n",
      "loss is:  1.3657265\n",
      "loss is:  1.3655517\n",
      "loss is:  1.3653779\n",
      "loss is:  1.3652048\n",
      "loss is:  1.3650327\n",
      "loss is:  1.3648614\n",
      "loss is:  1.3646908\n",
      "loss is:  1.3645213\n",
      "loss is:  1.3643523\n",
      "loss is:  1.3641844\n",
      "loss is:  1.3640172\n",
      "loss is:  1.3638511\n",
      "loss is:  1.3636856\n",
      "loss is:  1.3635209\n",
      "loss is:  1.363357\n",
      "loss is:  1.3631941\n",
      "loss is:  1.3630317\n",
      "loss is:  1.3628703\n",
      "loss is:  1.3627098\n",
      "loss is:  1.36255\n",
      "loss is:  1.362391\n",
      "loss is:  1.3622328\n",
      "loss is:  1.3620752\n",
      "loss is:  1.3619186\n",
      "loss is:  1.3617628\n",
      "loss is:  1.3616077\n",
      "loss is:  1.3614534\n",
      "loss is:  1.3612998\n",
      "loss is:  1.3611469\n",
      "loss is:  1.3609952\n",
      "loss is:  1.3608438\n",
      "loss is:  1.3606931\n",
      "loss is:  1.3605434\n",
      "loss is:  1.3603945\n",
      "loss is:  1.3602461\n",
      "loss is:  1.3600985\n",
      "loss is:  1.3599517\n",
      "loss is:  1.3598056\n",
      "loss is:  1.3596601\n",
      "loss is:  1.3595155\n",
      "loss is:  1.3593718\n",
      "loss is:  1.3592285\n",
      "loss is:  1.359086\n",
      "loss is:  1.3589442\n",
      "loss is:  1.3588033\n",
      "loss is:  1.3586628\n",
      "loss is:  1.3585232\n",
      "loss is:  1.3583841\n",
      "loss is:  1.3582461\n",
      "loss is:  1.3581084\n",
      "loss is:  1.3579715\n",
      "loss is:  1.3578353\n",
      "loss is:  1.3576998\n",
      "loss is:  1.357565\n",
      "loss is:  1.3574307\n",
      "loss is:  1.3572972\n",
      "loss is:  1.3571644\n",
      "loss is:  1.3570322\n",
      "loss is:  1.3569007\n",
      "loss is:  1.3567698\n",
      "loss is:  1.3566395\n",
      "loss is:  1.3565099\n",
      "loss is:  1.3563809\n",
      "loss is:  1.3562528\n",
      "loss is:  1.3561251\n",
      "loss is:  1.3559982\n",
      "loss is:  1.3558718\n",
      "loss is:  1.355746\n",
      "loss is:  1.3556209\n",
      "loss is:  1.3554964\n",
      "loss is:  1.3553724\n",
      "loss is:  1.3552492\n",
      "loss is:  1.3551265\n",
      "loss is:  1.3550044\n",
      "loss is:  1.354883\n",
      "loss is:  1.3547621\n",
      "loss is:  1.3546419\n",
      "loss is:  1.3545221\n",
      "loss is:  1.3544031\n",
      "loss is:  1.3542848\n",
      "loss is:  1.3541669\n",
      "loss is:  1.3540494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  1.3539326\n",
      "loss is:  1.3538166\n",
      "loss is:  1.3537011\n",
      "loss is:  1.353586\n",
      "loss is:  1.3534718\n",
      "loss is:  1.3533578\n",
      "loss is:  1.3532444\n",
      "loss is:  1.3531317\n",
      "loss is:  1.3530195\n",
      "loss is:  1.3529079\n",
      "loss is:  1.3527969\n",
      "loss is:  1.3526863\n",
      "loss is:  1.3525763\n",
      "loss is:  1.3524668\n",
      "loss is:  1.3523579\n",
      "loss is:  1.3522495\n",
      "loss is:  1.3521416\n",
      "loss is:  1.3520343\n",
      "loss is:  1.3519275\n",
      "loss is:  1.3518212\n",
      "loss is:  1.3517154\n",
      "loss is:  1.3516101\n",
      "loss is:  1.3515055\n",
      "loss is:  1.3514012\n",
      "loss is:  1.3512976\n",
      "loss is:  1.3511944\n",
      "loss is:  1.3510917\n",
      "loss is:  1.3509893\n",
      "loss is:  1.3508878\n",
      "loss is:  1.3507866\n",
      "loss is:  1.3506858\n",
      "loss is:  1.3505856\n",
      "loss is:  1.3504858\n",
      "loss is:  1.3503866\n",
      "loss is:  1.3502877\n",
      "loss is:  1.3501894\n",
      "loss is:  1.3500917\n",
      "loss is:  1.3499944\n",
      "loss is:  1.3498975\n",
      "loss is:  1.3498011\n",
      "loss is:  1.3497053\n",
      "loss is:  1.3496097\n",
      "loss is:  1.3495147\n",
      "loss is:  1.3494201\n",
      "loss is:  1.3493261\n",
      "loss is:  1.3492323\n",
      "loss is:  1.3491392\n",
      "loss is:  1.3490465\n",
      "loss is:  1.3489541\n",
      "loss is:  1.3488624\n",
      "loss is:  1.3487709\n",
      "loss is:  1.3486798\n",
      "loss is:  1.3485893\n",
      "loss is:  1.3484993\n",
      "loss is:  1.3484094\n",
      "loss is:  1.3483204\n",
      "loss is:  1.3482313\n",
      "loss is:  1.348143\n",
      "loss is:  1.348055\n",
      "loss is:  1.3479674\n",
      "loss is:  1.3478804\n",
      "loss is:  1.3477936\n",
      "loss is:  1.3477073\n",
      "loss is:  1.3476212\n",
      "loss is:  1.3475358\n",
      "loss is:  1.3474507\n",
      "loss is:  1.3473661\n",
      "loss is:  1.3472816\n",
      "loss is:  1.3471978\n",
      "loss is:  1.3471143\n",
      "loss is:  1.3470311\n",
      "loss is:  1.3469485\n",
      "loss is:  1.346866\n",
      "loss is:  1.3467841\n",
      "loss is:  1.3467025\n",
      "loss is:  1.3466215\n",
      "loss is:  1.3465405\n",
      "loss is:  1.3464601\n",
      "loss is:  1.3463802\n",
      "loss is:  1.3463006\n",
      "loss is:  1.3462212\n",
      "loss is:  1.3461422\n",
      "loss is:  1.3460637\n",
      "loss is:  1.3459854\n",
      "loss is:  1.3459076\n",
      "loss is:  1.3458302\n",
      "loss is:  1.3457533\n",
      "loss is:  1.3456763\n",
      "loss is:  1.3456\n",
      "loss is:  1.345524\n",
      "loss is:  1.3454483\n",
      "loss is:  1.3453728\n",
      "loss is:  1.3452978\n",
      "loss is:  1.3452233\n",
      "loss is:  1.345149\n",
      "loss is:  1.345075\n",
      "loss is:  1.3450013\n",
      "loss is:  1.344928\n",
      "loss is:  1.3448551\n",
      "loss is:  1.3447825\n",
      "loss is:  1.3447102\n",
      "loss is:  1.3446381\n",
      "loss is:  1.3445666\n",
      "loss is:  1.3444953\n",
      "loss is:  1.3444245\n",
      "loss is:  1.3443537\n",
      "loss is:  1.3442833\n",
      "loss is:  1.3442134\n",
      "loss is:  1.3441437\n",
      "loss is:  1.3440744\n",
      "loss is:  1.3440053\n",
      "loss is:  1.3439366\n",
      "loss is:  1.343868\n",
      "loss is:  1.3438\n",
      "loss is:  1.3437324\n",
      "loss is:  1.3436646\n",
      "loss is:  1.3435974\n",
      "loss is:  1.3435307\n",
      "loss is:  1.3434639\n",
      "loss is:  1.3433976\n",
      "loss is:  1.3433316\n",
      "loss is:  1.3432659\n",
      "loss is:  1.3432006\n",
      "loss is:  1.3431355\n",
      "loss is:  1.3430705\n",
      "loss is:  1.343006\n",
      "loss is:  1.3429419\n",
      "loss is:  1.3428777\n",
      "loss is:  1.3428143\n",
      "loss is:  1.3427508\n",
      "loss is:  1.3426877\n",
      "loss is:  1.3426248\n",
      "loss is:  1.3425622\n",
      "loss is:  1.3425\n",
      "loss is:  1.342438\n",
      "loss is:  1.3423762\n",
      "loss is:  1.3423147\n",
      "loss is:  1.3422536\n",
      "loss is:  1.3421926\n",
      "loss is:  1.3421319\n",
      "loss is:  1.3420714\n",
      "loss is:  1.3420115\n",
      "loss is:  1.3419516\n",
      "loss is:  1.3418919\n",
      "loss is:  1.3418326\n",
      "loss is:  1.3417735\n",
      "loss is:  1.3417149\n",
      "loss is:  1.3416562\n",
      "loss is:  1.3415978\n",
      "loss is:  1.3415397\n",
      "loss is:  1.3414819\n",
      "loss is:  1.3414243\n",
      "loss is:  1.341367\n",
      "loss is:  1.3413099\n",
      "loss is:  1.3412532\n",
      "loss is:  1.3411967\n",
      "loss is:  1.3411403\n",
      "loss is:  1.3410842\n",
      "loss is:  1.3410283\n",
      "loss is:  1.3409728\n",
      "loss is:  1.3409175\n",
      "loss is:  1.3408624\n",
      "loss is:  1.3408073\n",
      "loss is:  1.3407526\n",
      "loss is:  1.3406984\n",
      "loss is:  1.3406441\n",
      "loss is:  1.3405901\n",
      "loss is:  1.3405364\n",
      "loss is:  1.340483\n",
      "loss is:  1.3404297\n",
      "loss is:  1.3403766\n",
      "loss is:  1.3403237\n",
      "loss is:  1.3402711\n",
      "loss is:  1.3402187\n",
      "loss is:  1.3401667\n",
      "loss is:  1.3401147\n",
      "loss is:  1.340063\n",
      "loss is:  1.3400115\n",
      "loss is:  1.3399601\n",
      "loss is:  1.3399091\n",
      "loss is:  1.3398582\n",
      "loss is:  1.3398075\n",
      "loss is:  1.3397571\n",
      "loss is:  1.3397069\n",
      "loss is:  1.339657\n",
      "loss is:  1.339607\n",
      "loss is:  1.3395575\n",
      "loss is:  1.3395082\n",
      "loss is:  1.339459\n",
      "loss is:  1.33941\n",
      "loss is:  1.3393612\n",
      "loss is:  1.3393126\n",
      "loss is:  1.3392642\n",
      "loss is:  1.3392159\n",
      "loss is:  1.339168\n",
      "loss is:  1.3391201\n",
      "loss is:  1.3390727\n",
      "loss is:  1.3390253\n",
      "loss is:  1.3389782\n",
      "loss is:  1.3389311\n",
      "loss is:  1.3388844\n",
      "loss is:  1.3388377\n",
      "loss is:  1.3387913\n",
      "loss is:  1.338745\n",
      "loss is:  1.3386989\n",
      "loss is:  1.338653\n",
      "loss is:  1.3386074\n",
      "loss is:  1.338562\n",
      "loss is:  1.3385166\n",
      "loss is:  1.3384714\n",
      "loss is:  1.3384265\n",
      "loss is:  1.3383818\n",
      "loss is:  1.3383372\n",
      "loss is:  1.3382927\n",
      "loss is:  1.3382485\n",
      "loss is:  1.3382044\n",
      "loss is:  1.3381606\n",
      "loss is:  1.338117\n",
      "loss is:  1.3380735\n",
      "loss is:  1.3380301\n",
      "loss is:  1.337987\n",
      "loss is:  1.3379439\n",
      "loss is:  1.3379011\n",
      "loss is:  1.3378584\n",
      "loss is:  1.3378159\n",
      "loss is:  1.3377737\n",
      "loss is:  1.3377315\n",
      "loss is:  1.3376894\n",
      "loss is:  1.3376477\n",
      "loss is:  1.3376061\n",
      "loss is:  1.3375645\n",
      "loss is:  1.3375232\n",
      "loss is:  1.337482\n",
      "loss is:  1.337441\n",
      "loss is:  1.3374002\n",
      "loss is:  1.3373594\n",
      "loss is:  1.337319\n",
      "loss is:  1.3372787\n",
      "loss is:  1.3372384\n",
      "loss is:  1.3371984\n",
      "loss is:  1.3371584\n",
      "loss is:  1.3371187\n",
      "loss is:  1.3370792\n",
      "loss is:  1.3370397\n",
      "loss is:  1.3370005\n",
      "loss is:  1.3369614\n",
      "loss is:  1.3369225\n",
      "loss is:  1.3368837\n",
      "loss is:  1.3368448\n",
      "loss is:  1.3368063\n",
      "loss is:  1.336768\n",
      "loss is:  1.33673\n",
      "loss is:  1.3366917\n",
      "loss is:  1.3366537\n",
      "loss is:  1.3366159\n",
      "loss is:  1.3365784\n",
      "loss is:  1.3365408\n",
      "loss is:  1.3365035\n",
      "loss is:  1.3364666\n",
      "loss is:  1.3364291\n",
      "loss is:  1.3363923\n",
      "loss is:  1.3363553\n",
      "loss is:  1.3363187\n",
      "loss is:  1.3362823\n",
      "loss is:  1.336246\n",
      "loss is:  1.3362097\n",
      "loss is:  1.3361735\n",
      "loss is:  1.3361377\n",
      "loss is:  1.3361019\n",
      "loss is:  1.3360661\n",
      "loss is:  1.3360307\n",
      "loss is:  1.3359952\n",
      "loss is:  1.3359599\n",
      "loss is:  1.3359249\n",
      "loss is:  1.3358898\n",
      "loss is:  1.3358548\n",
      "loss is:  1.3358201\n",
      "loss is:  1.3357854\n",
      "loss is:  1.3357509\n",
      "loss is:  1.3357166\n",
      "loss is:  1.3356823\n",
      "loss is:  1.3356482\n",
      "loss is:  1.3356141\n",
      "loss is:  1.3355802\n",
      "loss is:  1.3355465\n",
      "loss is:  1.3355129\n",
      "loss is:  1.3354794\n",
      "loss is:  1.3354461\n",
      "loss is:  1.3354127\n",
      "loss is:  1.3353796\n",
      "loss is:  1.3353466\n",
      "loss is:  1.3353137\n",
      "loss is:  1.335281\n",
      "loss is:  1.3352482\n",
      "loss is:  1.3352158\n",
      "loss is:  1.3351833\n",
      "loss is:  1.335151\n",
      "loss is:  1.3351189\n",
      "loss is:  1.3350868\n",
      "loss is:  1.3350549\n",
      "loss is:  1.335023\n",
      "loss is:  1.3349915\n",
      "loss is:  1.3349597\n",
      "loss is:  1.3349283\n",
      "loss is:  1.3348969\n",
      "loss is:  1.3348656\n",
      "loss is:  1.3348345\n",
      "loss is:  1.3348035\n",
      "loss is:  1.3347726\n",
      "loss is:  1.3347418\n",
      "loss is:  1.334711\n",
      "loss is:  1.3346804\n",
      "loss is:  1.3346499\n",
      "loss is:  1.3346196\n",
      "loss is:  1.3345894\n",
      "loss is:  1.3345592\n",
      "loss is:  1.3345292\n",
      "loss is:  1.3344992\n",
      "loss is:  1.3344693\n",
      "loss is:  1.3344395\n",
      "loss is:  1.33441\n",
      "loss is:  1.3343804\n",
      "loss is:  1.3343511\n",
      "loss is:  1.3343219\n",
      "loss is:  1.3342925\n",
      "loss is:  1.3342634\n",
      "loss is:  1.3342345\n",
      "loss is:  1.3342055\n",
      "loss is:  1.3341768\n",
      "loss is:  1.3341479\n",
      "loss is:  1.3341194\n",
      "loss is:  1.3340908\n",
      "loss is:  1.3340626\n",
      "loss is:  1.3340342\n",
      "loss is:  1.3340061\n",
      "loss is:  1.3339778\n",
      "loss is:  1.3339499\n",
      "loss is:  1.3339219\n",
      "loss is:  1.333894\n",
      "loss is:  1.3338665\n",
      "loss is:  1.3338388\n",
      "loss is:  1.3338114\n",
      "loss is:  1.3337839\n",
      "loss is:  1.3337564\n",
      "loss is:  1.3337294\n",
      "loss is:  1.3337021\n",
      "loss is:  1.3336749\n",
      "loss is:  1.333648\n",
      "loss is:  1.3336211\n",
      "loss is:  1.3335944\n",
      "loss is:  1.3335676\n",
      "loss is:  1.333541\n",
      "loss is:  1.3335146\n",
      "loss is:  1.3334881\n",
      "loss is:  1.3334619\n",
      "loss is:  1.3334357\n",
      "loss is:  1.3334094\n",
      "loss is:  1.3333836\n",
      "loss is:  1.3333575\n",
      "loss is:  1.3333316\n",
      "loss is:  1.3333058\n",
      "loss is:  1.33328\n",
      "loss is:  1.3332545\n",
      "loss is:  1.3332288\n",
      "loss is:  1.3332034\n",
      "loss is:  1.3331782\n",
      "loss is:  1.3331528\n",
      "loss is:  1.3331275\n",
      "loss is:  1.3331025\n",
      "loss is:  1.3330775\n",
      "loss is:  1.3330525\n",
      "loss is:  1.3330277\n",
      "loss is:  1.3330029\n",
      "loss is:  1.3329781\n",
      "loss is:  1.3329535\n",
      "loss is:  1.3329289\n",
      "loss is:  1.3329045\n",
      "loss is:  1.3328801\n",
      "loss is:  1.3328559\n",
      "loss is:  1.3328316\n",
      "loss is:  1.3328075\n",
      "loss is:  1.3327835\n",
      "loss is:  1.3327595\n",
      "loss is:  1.3327357\n",
      "loss is:  1.3327117\n",
      "loss is:  1.3326881\n",
      "loss is:  1.3326643\n",
      "loss is:  1.3326406\n",
      "loss is:  1.3326172\n",
      "loss is:  1.3325938\n",
      "loss is:  1.3325704\n",
      "loss is:  1.3325472\n",
      "loss is:  1.3325241\n",
      "loss is:  1.3325008\n",
      "loss is:  1.3324778\n",
      "loss is:  1.3324548\n",
      "loss is:  1.332432\n",
      "loss is:  1.332409\n",
      "loss is:  1.3323864\n",
      "loss is:  1.3323636\n",
      "loss is:  1.332341\n",
      "loss is:  1.3323183\n",
      "loss is:  1.332296\n",
      "loss is:  1.3322735\n",
      "loss is:  1.3322514\n",
      "loss is:  1.3322289\n",
      "loss is:  1.3322068\n",
      "loss is:  1.3321848\n",
      "loss is:  1.3321627\n",
      "loss is:  1.3321408\n",
      "loss is:  1.3321187\n",
      "loss is:  1.332097\n",
      "loss is:  1.3320752\n",
      "loss is:  1.3320534\n",
      "loss is:  1.332032\n",
      "loss is:  1.3320103\n",
      "loss is:  1.3319889\n",
      "loss is:  1.3319674\n",
      "loss is:  1.3319461\n",
      "loss is:  1.3319249\n",
      "loss is:  1.3319037\n",
      "loss is:  1.3318824\n",
      "loss is:  1.3318614\n",
      "loss is:  1.3318404\n",
      "loss is:  1.3318193\n",
      "loss is:  1.3317986\n",
      "loss is:  1.3317777\n",
      "loss is:  1.3317571\n",
      "loss is:  1.3317362\n",
      "loss is:  1.3317156\n",
      "loss is:  1.3316951\n",
      "loss is:  1.3316746\n",
      "loss is:  1.3316541\n",
      "loss is:  1.3316336\n",
      "loss is:  1.3316135\n",
      "loss is:  1.3315933\n",
      "loss is:  1.331573\n",
      "loss is:  1.3315529\n",
      "loss is:  1.3315328\n",
      "loss is:  1.3315128\n",
      "loss is:  1.3314928\n",
      "loss is:  1.3314729\n",
      "loss is:  1.3314532\n",
      "loss is:  1.3314333\n",
      "loss is:  1.3314137\n",
      "loss is:  1.3313942\n",
      "loss is:  1.3313745\n",
      "loss is:  1.331355\n",
      "loss is:  1.3313355\n",
      "loss is:  1.3313161\n",
      "loss is:  1.3312967\n",
      "loss is:  1.3312775\n",
      "loss is:  1.3312583\n",
      "loss is:  1.3312391\n",
      "loss is:  1.33122\n",
      "loss is:  1.331201\n",
      "loss is:  1.331182\n",
      "loss is:  1.331163\n",
      "loss is:  1.3311441\n",
      "loss is:  1.3311254\n"
     ]
    }
   ],
   "source": [
    "n_iters = 1000\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    print('loss is: ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train} ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35916016  0.21275197 -1.2531048  -1.1059759  -1.7222703 ]\n",
      " [-1.64989    -1.1994785  -0.75585455  1.464288   -0.18662998]\n",
      " [ 0.4316211   0.24706587  0.18025362 -0.16986072  0.814561  ]\n",
      " [-0.8777746  -0.05945565  1.2594256  -0.51478124 -0.635934  ]\n",
      " [ 3.0930665   0.07628312 -0.26005045  1.3107793  -0.16534917]\n",
      " [-1.1520251   1.0098528   0.55358887 -0.5931492   0.80558366]\n",
      " [-0.34872076 -0.22793616  1.1563816  -0.50491685 -2.156127  ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6679405   1.7584124  -1.9933364  -1.0066311  -2.0391376 ]\n",
      " [-0.62278926  0.34618187 -1.4960862   1.5636327  -0.50349724]\n",
      " [ 1.4587218   1.7927263  -0.55997807 -0.07051596  0.49769372]\n",
      " [ 0.14932609  1.4862047   0.51919395 -0.41543648 -0.9528013 ]\n",
      " [ 4.1201673   1.6219435  -1.0002822   1.4101241  -0.48221648]\n",
      " [-0.12492442  2.5555131  -0.18664283 -0.49380443  0.48871636]\n",
      " [ 0.6783799   1.3177242   0.4161499  -0.4055721  -2.4729943 ]]\n"
     ]
    }
   ],
   "source": [
    "vectors = sess.run(w1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4587218   1.7927263  -0.55997807 -0.07051596  0.49769372]\n"
     ]
    }
   ],
   "source": [
    "print( vectors[ word2int['queen'] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum( (vec1-vec2)**2 ) )\n",
    "\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # lo act like pos infinity\n",
    "    min_index  = -1\n",
    "    \n",
    "    query_vector = vectors[word_index]\n",
    "    \n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "            \n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen\n",
      "king\n",
      "she\n"
     ]
    }
   ],
   "source": [
    "print(int2word[find_closest(word2int['king'], vectors)])\n",
    "print(int2word[find_closest(word2int['queen'], vectors)])\n",
    "print(int2word[find_closest(word2int['royal'], vectors)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "corpus = \"बिहीबार ४ जनाले जिल्ला अदालत मोरङसमक्ष थुनछेक बहस गरेका थिए । थप ३ जनाले शुक्रबार बहस गर्दै उपलब्ध प्रमाणका आधारमा प्रतिवादीहरु कसुरदार देखिएको भन्दै थुनामै राखेर थप अनुसन्धान र कारबाही अघि \"\n",
    "# corpus_raw = corpus.lower() # converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['बिहीबार', '४', 'जनाले', 'जिल्ला', 'अदालत', 'मोरङसमक्ष', 'थुनछेक', 'बहस', 'गरेका', 'थिए', '।', 'थप', '३', 'जनाले', 'शुक्रबार', 'बहस', 'गर्दै', 'उपलब्ध', 'प्रमाणका', 'आधारमा', 'प्रतिवादीहरु', 'कसुरदार', 'देखिएको', 'भन्दै', 'थुनामै', 'राखेर', 'थप', 'अनुसन्धान', 'र', 'कारबाही', 'अघि']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_raw.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'शुक्रबार', 'राखेर', 'प्रतिवादीहरु', 'आधारमा', 'उपलब्ध', 'थिए', 'बिहीबार', 'जिल्ला', 'अघि', 'थुनछेक', 'अनुसन्धान', 'थुनामै', 'अदालत', 'प्रमाणका', 'गरेका', 'जनाले', 'र', 'कसुरदार', '३', 'भन्दै', 'थप', 'मोरङसमक्ष', 'बहस', 'कारबाही', 'देखिएको', '४', 'गर्दै'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning the raw corpus and removing the duplicates\n",
    "words = []\n",
    "for word in corpus_raw.split():\n",
    "    if word != '।': # we dont want to treat . as a word\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words) # remove all the duplicate words\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "\n",
    "vocab_size = len(words)\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "    \n",
    "print(word2int['शुक्रबार'])\n",
    "\n",
    "# print(int2word[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['बिहीबार', '४', 'जनाले', 'जिल्ला', 'अदालत', 'मोरङसमक्ष', 'थुनछेक', 'बहस', 'गरेका', 'थिए'], ['थप', '३', 'जनाले', 'शुक्रबार', 'बहस', 'गर्दै', 'उपलब्ध', 'प्रमाणका', 'आधारमा', 'प्रतिवादीहरु', 'कसुरदार', 'देखिएको', 'भन्दै', 'थुनामै', 'राखेर', 'थप', 'अनुसन्धान', 'र', 'कारबाही', 'अघि']]\n"
     ]
    }
   ],
   "source": [
    "# splitting the sentences into arrays\n",
    "raw_sentences = corpus_raw.split('।')\n",
    "sentences = []\n",
    "\n",
    "for sentence in raw_sentences:\n",
    "    sentences.append(sentence.split())\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the word pair: \n",
      "[['शुक्रबार', 'बिहीबार'], ['शुक्रबार', '४'], ['शुक्रबार', 'जनाले'], ['राखेर', 'बिहीबार'], ['राखेर', '४'], ['राखेर', 'जनाले'], ['राखेर', 'जिल्ला'], ['प्रतिवादीहरु', 'बिहीबार'], ['प्रतिवादीहरु', '४'], ['प्रतिवादीहरु', 'जनाले'], ['प्रतिवादीहरु', 'जिल्ला'], ['प्रतिवादीहरु', 'अदालत'], ['आधारमा', '४'], ['आधारमा', 'जनाले'], ['आधारमा', 'जिल्ला'], ['आधारमा', 'अदालत'], ['आधारमा', 'मोरङसमक्ष'], ['उपलब्ध', 'जनाले'], ['उपलब्ध', 'जिल्ला'], ['उपलब्ध', 'अदालत'], ['उपलब्ध', 'मोरङसमक्ष'], ['उपलब्ध', 'थुनछेक'], ['थिए', 'जिल्ला'], ['थिए', 'अदालत'], ['थिए', 'मोरङसमक्ष'], ['थिए', 'थुनछेक'], ['थिए', 'बहस'], ['बिहीबार', 'अदालत'], ['बिहीबार', 'मोरङसमक्ष'], ['बिहीबार', 'थुनछेक'], ['बिहीबार', 'बहस'], ['बिहीबार', 'गरेका'], ['जिल्ला', 'मोरङसमक्ष'], ['जिल्ला', 'थुनछेक'], ['जिल्ला', 'बहस'], ['जिल्ला', 'गरेका'], ['जिल्ला', 'थिए'], ['अघि', 'थुनछेक'], ['अघि', 'बहस'], ['अघि', 'गरेका'], ['अघि', 'थिए'], ['थुनछेक', 'बहस'], ['थुनछेक', 'गरेका'], ['थुनछेक', 'थिए'], ['अनुसन्धान', 'गरेका'], ['अनुसन्धान', 'थिए'], ['थुनामै', 'थिए'], ['शुक्रबार', 'थप'], ['शुक्रबार', '३'], ['शुक्रबार', 'जनाले'], ['राखेर', 'थप'], ['राखेर', '३'], ['राखेर', 'जनाले'], ['राखेर', 'शुक्रबार'], ['प्रतिवादीहरु', 'थप'], ['प्रतिवादीहरु', '३'], ['प्रतिवादीहरु', 'जनाले'], ['प्रतिवादीहरु', 'शुक्रबार'], ['प्रतिवादीहरु', 'बहस'], ['आधारमा', '३'], ['आधारमा', 'जनाले'], ['आधारमा', 'शुक्रबार'], ['आधारमा', 'बहस'], ['आधारमा', 'गर्दै'], ['उपलब्ध', 'जनाले'], ['उपलब्ध', 'शुक्रबार'], ['उपलब्ध', 'बहस'], ['उपलब्ध', 'गर्दै'], ['थिए', 'शुक्रबार'], ['थिए', 'बहस'], ['थिए', 'गर्दै'], ['थिए', 'उपलब्ध'], ['थिए', 'प्रमाणका'], ['बिहीबार', 'बहस'], ['बिहीबार', 'गर्दै'], ['बिहीबार', 'उपलब्ध'], ['बिहीबार', 'प्रमाणका'], ['बिहीबार', 'आधारमा'], ['जिल्ला', 'गर्दै'], ['जिल्ला', 'उपलब्ध'], ['जिल्ला', 'प्रमाणका'], ['जिल्ला', 'आधारमा'], ['जिल्ला', 'प्रतिवादीहरु'], ['अघि', 'उपलब्ध'], ['अघि', 'प्रमाणका'], ['अघि', 'आधारमा'], ['अघि', 'प्रतिवादीहरु'], ['अघि', 'कसुरदार'], ['थुनछेक', 'प्रमाणका'], ['थुनछेक', 'आधारमा'], ['थुनछेक', 'प्रतिवादीहरु'], ['थुनछेक', 'कसुरदार'], ['थुनछेक', 'देखिएको'], ['अनुसन्धान', 'आधारमा'], ['अनुसन्धान', 'प्रतिवादीहरु'], ['अनुसन्धान', 'कसुरदार'], ['अनुसन्धान', 'देखिएको'], ['अनुसन्धान', 'भन्दै'], ['थुनामै', 'प्रतिवादीहरु'], ['थुनामै', 'कसुरदार'], ['थुनामै', 'देखिएको'], ['थुनामै', 'भन्दै'], ['अदालत', 'कसुरदार'], ['अदालत', 'देखिएको'], ['अदालत', 'भन्दै'], ['अदालत', 'थुनामै'], ['अदालत', 'राखेर'], ['प्रमाणका', 'देखिएको'], ['प्रमाणका', 'भन्दै'], ['प्रमाणका', 'थुनामै'], ['प्रमाणका', 'राखेर'], ['प्रमाणका', 'थप'], ['गरेका', 'भन्दै'], ['गरेका', 'थुनामै'], ['गरेका', 'राखेर'], ['गरेका', 'थप'], ['गरेका', 'अनुसन्धान'], ['जनाले', 'थुनामै'], ['जनाले', 'राखेर'], ['जनाले', 'थप'], ['जनाले', 'अनुसन्धान'], ['जनाले', 'र'], ['र', 'राखेर'], ['र', 'थप'], ['र', 'अनुसन्धान'], ['र', 'कारबाही'], ['कसुरदार', 'थप'], ['कसुरदार', 'अनुसन्धान'], ['कसुरदार', 'र'], ['कसुरदार', 'कारबाही'], ['कसुरदार', 'अघि'], ['३', 'अनुसन्धान'], ['३', 'र'], ['३', 'कारबाही'], ['३', 'अघि'], ['भन्दै', 'र'], ['भन्दै', 'कारबाही'], ['भन्दै', 'अघि'], ['थप', 'कारबाही'], ['थप', 'अघि'], ['मोरङसमक्ष', 'अघि']]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "WINDOW_SIZE = 2\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(words):\n",
    "        for nb_word in sentence[max(word_index- WINDOW_SIZE, 0) : min(word_index+WINDOW_SIZE, len(sentence)) + 1]:\n",
    "            if nb_word != word:\n",
    "                data.append([word, nb_word])\n",
    "print('Generating the word pair: ')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "# now convert all to one_hot_vectors\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp\n",
    "\n",
    "x_train = [] # input_word\n",
    "y_train = [] # output_word\n",
    "\n",
    "for data_word in data:\n",
    "    x_train.append(to_one_hot( word2int[ data_word[0] ], vocab_size ) ) # convert to one_hot using the index returned from word2int\n",
    "    y_train.append(to_one_hot( word2int[ data_word[1] ], vocab_size ) )\n",
    "    \n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to numpy array: \n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "print('Converting to numpy array: ')\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 27) (141, 27)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make tensorflow placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding networks weight and biases\n",
    "EMBEDDING_DIM = 5\n",
    "\n",
    "w1 = tf.Variable( tf.random_normal([vocab_size, EMBEDDING_DIM]) ) #weight\n",
    "b1 = tf.Variable( tf.random_normal([EMBEDDING_DIM]) ) #bias\n",
    "\n",
    "hidden_representation = tf.add( tf.matmul(x, w1), b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable( tf.random_normal([EMBEDDING_DIM, vocab_size]) )\n",
    "b2 = tf.Variable( tf.random_normal( [vocab_size] ))\n",
    "\n",
    "prediction = tf.nn.softmax( tf.add( tf.matmul(hidden_representation, w2), b2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we train the neural network\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]) )\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  6.3328037\n",
      "loss is:  6.048159\n",
      "loss is:  5.832963\n",
      "loss is:  5.666474\n",
      "loss is:  5.5345235\n",
      "loss is:  5.427516\n",
      "loss is:  5.338858\n",
      "loss is:  5.263923\n",
      "loss is:  5.199395\n",
      "loss is:  5.1428595\n",
      "loss is:  5.0925274\n",
      "loss is:  5.047065\n",
      "loss is:  5.0054646\n",
      "loss is:  4.9669647\n",
      "loss is:  4.930985\n",
      "loss is:  4.897078\n",
      "loss is:  4.8649\n",
      "loss is:  4.8341856\n",
      "loss is:  4.804729\n",
      "loss is:  4.7763667\n",
      "loss is:  4.7489705\n",
      "loss is:  4.7224393\n",
      "loss is:  4.6966906\n",
      "loss is:  4.671658\n",
      "loss is:  4.6472864\n",
      "loss is:  4.6235313\n",
      "loss is:  4.6003532\n",
      "loss is:  4.57772\n",
      "loss is:  4.555605\n",
      "loss is:  4.533981\n",
      "loss is:  4.512828\n",
      "loss is:  4.492125\n",
      "loss is:  4.4718556\n",
      "loss is:  4.452002\n",
      "loss is:  4.4325504\n",
      "loss is:  4.4134865\n",
      "loss is:  4.3947964\n",
      "loss is:  4.3764687\n",
      "loss is:  4.358491\n",
      "loss is:  4.3408527\n",
      "loss is:  4.3235426\n",
      "loss is:  4.3065515\n",
      "loss is:  4.2898693\n",
      "loss is:  4.2734866\n",
      "loss is:  4.257394\n",
      "loss is:  4.241583\n",
      "loss is:  4.2260466\n",
      "loss is:  4.210776\n",
      "loss is:  4.195763\n",
      "loss is:  4.1810017\n",
      "loss is:  4.1664844\n",
      "loss is:  4.152204\n",
      "loss is:  4.1381536\n",
      "loss is:  4.1243286\n",
      "loss is:  4.1107216\n",
      "loss is:  4.097327\n",
      "loss is:  4.08414\n",
      "loss is:  4.071154\n",
      "loss is:  4.0583644\n",
      "loss is:  4.0457664\n",
      "loss is:  4.033355\n",
      "loss is:  4.0211263\n",
      "loss is:  4.0090747\n",
      "loss is:  3.9971972\n",
      "loss is:  3.9854884\n",
      "loss is:  3.9739454\n",
      "loss is:  3.9625642\n",
      "loss is:  3.9513407\n",
      "loss is:  3.9402716\n",
      "loss is:  3.9293542\n",
      "loss is:  3.9185848\n",
      "loss is:  3.907959\n",
      "loss is:  3.8974762\n",
      "loss is:  3.8871307\n",
      "loss is:  3.8769224\n",
      "loss is:  3.8668468\n",
      "loss is:  3.856902\n",
      "loss is:  3.8470848\n",
      "loss is:  3.8373928\n",
      "loss is:  3.8278236\n",
      "loss is:  3.8183758\n",
      "loss is:  3.8090456\n",
      "loss is:  3.7998323\n",
      "loss is:  3.7907329\n",
      "loss is:  3.7817447\n",
      "loss is:  3.7728674\n",
      "loss is:  3.7640975\n",
      "loss is:  3.7554338\n",
      "loss is:  3.7468743\n",
      "loss is:  3.7384167\n",
      "loss is:  3.7300596\n",
      "loss is:  3.7218018\n",
      "loss is:  3.7136405\n",
      "loss is:  3.7055745\n",
      "loss is:  3.6976025\n",
      "loss is:  3.6897223\n",
      "loss is:  3.6819336\n",
      "loss is:  3.6742332\n",
      "loss is:  3.6666203\n",
      "loss is:  3.6590943\n",
      "loss is:  3.6516523\n",
      "loss is:  3.6442935\n",
      "loss is:  3.6370175\n",
      "loss is:  3.6298208\n",
      "loss is:  3.6227043\n",
      "loss is:  3.6156652\n",
      "loss is:  3.6087027\n",
      "loss is:  3.601816\n",
      "loss is:  3.595003\n",
      "loss is:  3.5882633\n",
      "loss is:  3.5815957\n",
      "loss is:  3.574998\n",
      "loss is:  3.5684698\n",
      "loss is:  3.56201\n",
      "loss is:  3.555618\n",
      "loss is:  3.5492916\n",
      "loss is:  3.5430305\n",
      "loss is:  3.5368333\n",
      "loss is:  3.5306993\n",
      "loss is:  3.524627\n",
      "loss is:  3.5186157\n",
      "loss is:  3.5126648\n",
      "loss is:  3.5067723\n",
      "loss is:  3.5009384\n",
      "loss is:  3.4951618\n",
      "loss is:  3.4894412\n",
      "loss is:  3.4837759\n",
      "loss is:  3.4781656\n",
      "loss is:  3.4726086\n",
      "loss is:  3.4671042\n",
      "loss is:  3.4616523\n",
      "loss is:  3.4562514\n",
      "loss is:  3.4509008\n",
      "loss is:  3.4455998\n",
      "loss is:  3.4403472\n",
      "loss is:  3.435143\n",
      "loss is:  3.4299858\n",
      "loss is:  3.4248753\n",
      "loss is:  3.4198105\n",
      "loss is:  3.414791\n",
      "loss is:  3.409816\n",
      "loss is:  3.4048843\n",
      "loss is:  3.3999958\n",
      "loss is:  3.3951497\n",
      "loss is:  3.3903458\n",
      "loss is:  3.3855827\n",
      "loss is:  3.3808603\n",
      "loss is:  3.3761773\n",
      "loss is:  3.3715339\n",
      "loss is:  3.3669293\n",
      "loss is:  3.3623626\n",
      "loss is:  3.3578336\n",
      "loss is:  3.3533418\n",
      "loss is:  3.3488865\n",
      "loss is:  3.344467\n",
      "loss is:  3.3400826\n",
      "loss is:  3.3357337\n",
      "loss is:  3.3314188\n",
      "loss is:  3.327138\n",
      "loss is:  3.3228903\n",
      "loss is:  3.3186758\n",
      "loss is:  3.314494\n",
      "loss is:  3.3103437\n",
      "loss is:  3.3062255\n",
      "loss is:  3.3021383\n",
      "loss is:  3.2980819\n",
      "loss is:  3.2940557\n",
      "loss is:  3.290059\n",
      "loss is:  3.286092\n",
      "loss is:  3.2821543\n",
      "loss is:  3.2782452\n",
      "loss is:  3.2743645\n",
      "loss is:  3.2705114\n",
      "loss is:  3.2666855\n",
      "loss is:  3.2628875\n",
      "loss is:  3.2591164\n",
      "loss is:  3.255371\n",
      "loss is:  3.2516522\n",
      "loss is:  3.2479591\n",
      "loss is:  3.2442918\n",
      "loss is:  3.2406495\n",
      "loss is:  3.2370315\n",
      "loss is:  3.2334383\n",
      "loss is:  3.2298694\n",
      "loss is:  3.2263246\n",
      "loss is:  3.2228029\n",
      "loss is:  3.2193048\n",
      "loss is:  3.2158298\n",
      "loss is:  3.2123773\n",
      "loss is:  3.208948\n",
      "loss is:  3.20554\n",
      "loss is:  3.2021544\n",
      "loss is:  3.19879\n",
      "loss is:  3.1954474\n",
      "loss is:  3.192126\n",
      "loss is:  3.1888256\n",
      "loss is:  3.1855457\n",
      "loss is:  3.1822863\n",
      "loss is:  3.1790473\n",
      "loss is:  3.1758277\n",
      "loss is:  3.1726284\n",
      "loss is:  3.1694486\n",
      "loss is:  3.1662877\n",
      "loss is:  3.1631463\n",
      "loss is:  3.1600237\n",
      "loss is:  3.1569197\n",
      "loss is:  3.153834\n",
      "loss is:  3.1507668\n",
      "loss is:  3.1477177\n",
      "loss is:  3.1446862\n",
      "loss is:  3.1416724\n",
      "loss is:  3.1386764\n",
      "loss is:  3.1356976\n",
      "loss is:  3.1327362\n",
      "loss is:  3.129791\n",
      "loss is:  3.1268628\n",
      "loss is:  3.1239517\n",
      "loss is:  3.1210563\n",
      "loss is:  3.1181777\n",
      "loss is:  3.1153152\n",
      "loss is:  3.1124682\n",
      "loss is:  3.1096373\n",
      "loss is:  3.1068218\n",
      "loss is:  3.1040215\n",
      "loss is:  3.1012368\n",
      "loss is:  3.098467\n",
      "loss is:  3.0957124\n",
      "loss is:  3.0929728\n",
      "loss is:  3.0902472\n",
      "loss is:  3.0875366\n",
      "loss is:  3.08484\n",
      "loss is:  3.082158\n",
      "loss is:  3.0794902\n",
      "loss is:  3.076836\n",
      "loss is:  3.0741959\n",
      "loss is:  3.0715694\n",
      "loss is:  3.0689564\n",
      "loss is:  3.0663567\n",
      "loss is:  3.0637705\n",
      "loss is:  3.0611973\n",
      "loss is:  3.0586371\n",
      "loss is:  3.0560899\n",
      "loss is:  3.0535553\n",
      "loss is:  3.0510337\n",
      "loss is:  3.0485244\n",
      "loss is:  3.0460277\n",
      "loss is:  3.043543\n",
      "loss is:  3.041071\n",
      "loss is:  3.0386107\n",
      "loss is:  3.0361621\n",
      "loss is:  3.0337257\n",
      "loss is:  3.0313008\n",
      "loss is:  3.0288875\n",
      "loss is:  3.0264862\n",
      "loss is:  3.024096\n",
      "loss is:  3.0217168\n",
      "loss is:  3.0193493\n",
      "loss is:  3.0169923\n",
      "loss is:  3.0146468\n",
      "loss is:  3.012312\n",
      "loss is:  3.0099878\n",
      "loss is:  3.0076742\n",
      "loss is:  3.0053716\n",
      "loss is:  3.003079\n",
      "loss is:  3.000797\n",
      "loss is:  2.998525\n",
      "loss is:  2.9962637\n",
      "loss is:  2.994012\n",
      "loss is:  2.9917707\n",
      "loss is:  2.9895387\n",
      "loss is:  2.987317\n",
      "loss is:  2.9851048\n",
      "loss is:  2.9829023\n",
      "loss is:  2.9807096\n",
      "loss is:  2.9785259\n",
      "loss is:  2.976352\n",
      "loss is:  2.974187\n",
      "loss is:  2.9720314\n",
      "loss is:  2.9698849\n",
      "loss is:  2.967747\n",
      "loss is:  2.9656188\n",
      "loss is:  2.9634988\n",
      "loss is:  2.9613879\n",
      "loss is:  2.9592855\n",
      "loss is:  2.957192\n",
      "loss is:  2.9551067\n",
      "loss is:  2.95303\n",
      "loss is:  2.9509618\n",
      "loss is:  2.9489024\n",
      "loss is:  2.9468505\n",
      "loss is:  2.9448066\n",
      "loss is:  2.9427714\n",
      "loss is:  2.9407434\n",
      "loss is:  2.9387243\n",
      "loss is:  2.9367127\n",
      "loss is:  2.9347086\n",
      "loss is:  2.9327128\n",
      "loss is:  2.9307241\n",
      "loss is:  2.9287436\n",
      "loss is:  2.9267707\n",
      "loss is:  2.9248047\n",
      "loss is:  2.922846\n",
      "loss is:  2.9208953\n",
      "loss is:  2.9189513\n",
      "loss is:  2.9170148\n",
      "loss is:  2.9150856\n",
      "loss is:  2.9131634\n",
      "loss is:  2.911248\n",
      "loss is:  2.9093397\n",
      "loss is:  2.9074385\n",
      "loss is:  2.9055438\n",
      "loss is:  2.9036562\n",
      "loss is:  2.9017751\n",
      "loss is:  2.8999012\n",
      "loss is:  2.8980331\n",
      "loss is:  2.8961725\n",
      "loss is:  2.894318\n",
      "loss is:  2.8924696\n",
      "loss is:  2.8906283\n",
      "loss is:  2.888793\n",
      "loss is:  2.886964\n",
      "loss is:  2.8851411\n",
      "loss is:  2.883325\n",
      "loss is:  2.8815148\n",
      "loss is:  2.8797104\n",
      "loss is:  2.8779125\n",
      "loss is:  2.8761206\n",
      "loss is:  2.8743343\n",
      "loss is:  2.8725543\n",
      "loss is:  2.87078\n",
      "loss is:  2.8690116\n",
      "loss is:  2.8672493\n",
      "loss is:  2.865492\n",
      "loss is:  2.863741\n",
      "loss is:  2.8619955\n",
      "loss is:  2.8602555\n",
      "loss is:  2.8585217\n",
      "loss is:  2.856793\n",
      "loss is:  2.8550696\n",
      "loss is:  2.8533523\n",
      "loss is:  2.8516397\n",
      "loss is:  2.849933\n",
      "loss is:  2.8482316\n",
      "loss is:  2.8465352\n",
      "loss is:  2.8448443\n",
      "loss is:  2.8431585\n",
      "loss is:  2.8414783\n",
      "loss is:  2.8398027\n",
      "loss is:  2.8381329\n",
      "loss is:  2.8364675\n",
      "loss is:  2.8348076\n",
      "loss is:  2.8331528\n",
      "loss is:  2.8315027\n",
      "loss is:  2.8298576\n",
      "loss is:  2.8282175\n",
      "loss is:  2.8265827\n",
      "loss is:  2.8249524\n",
      "loss is:  2.8233268\n",
      "loss is:  2.8217063\n",
      "loss is:  2.8200905\n",
      "loss is:  2.8184793\n",
      "loss is:  2.8168726\n",
      "loss is:  2.8152711\n",
      "loss is:  2.813674\n",
      "loss is:  2.8120818\n",
      "loss is:  2.810494\n",
      "loss is:  2.8089108\n",
      "loss is:  2.807332\n",
      "loss is:  2.805758\n",
      "loss is:  2.8041885\n",
      "loss is:  2.802623\n",
      "loss is:  2.8010626\n",
      "loss is:  2.799506\n",
      "loss is:  2.797954\n",
      "loss is:  2.7964067\n",
      "loss is:  2.7948632\n",
      "loss is:  2.7933247\n",
      "loss is:  2.79179\n",
      "loss is:  2.7902596\n",
      "loss is:  2.7887332\n",
      "loss is:  2.7872114\n",
      "loss is:  2.7856934\n",
      "loss is:  2.78418\n",
      "loss is:  2.7826707\n",
      "loss is:  2.7811656\n",
      "loss is:  2.7796643\n",
      "loss is:  2.778167\n",
      "loss is:  2.7766738\n",
      "loss is:  2.7751849\n",
      "loss is:  2.7737\n",
      "loss is:  2.7722187\n",
      "loss is:  2.7707415\n",
      "loss is:  2.7692685\n",
      "loss is:  2.7677994\n",
      "loss is:  2.7663338\n",
      "loss is:  2.7648723\n",
      "loss is:  2.7634149\n",
      "loss is:  2.7619612\n",
      "loss is:  2.760511\n",
      "loss is:  2.759065\n",
      "loss is:  2.7576225\n",
      "loss is:  2.756184\n",
      "loss is:  2.754749\n",
      "loss is:  2.7533176\n",
      "loss is:  2.7518904\n",
      "loss is:  2.7504663\n",
      "loss is:  2.7490463\n",
      "loss is:  2.74763\n",
      "loss is:  2.7462168\n",
      "loss is:  2.7448072\n",
      "loss is:  2.7434018\n",
      "loss is:  2.7419996\n",
      "loss is:  2.740601\n",
      "loss is:  2.7392056\n",
      "loss is:  2.7378142\n",
      "loss is:  2.7364259\n",
      "loss is:  2.7350411\n",
      "loss is:  2.7336597\n",
      "loss is:  2.732282\n",
      "loss is:  2.7309074\n",
      "loss is:  2.7295363\n",
      "loss is:  2.728169\n",
      "loss is:  2.7268045\n",
      "loss is:  2.7254436\n",
      "loss is:  2.7240856\n",
      "loss is:  2.7227316\n",
      "loss is:  2.7213805\n",
      "loss is:  2.7200325\n",
      "loss is:  2.7186878\n",
      "loss is:  2.7173467\n",
      "loss is:  2.7160082\n",
      "loss is:  2.7146735\n",
      "loss is:  2.7133417\n",
      "loss is:  2.7120132\n",
      "loss is:  2.7106874\n",
      "loss is:  2.7093651\n",
      "loss is:  2.7080457\n",
      "loss is:  2.7067297\n",
      "loss is:  2.7054167\n",
      "loss is:  2.7041063\n",
      "loss is:  2.7027996\n",
      "loss is:  2.7014952\n",
      "loss is:  2.7001941\n",
      "loss is:  2.6988962\n",
      "loss is:  2.6976013\n",
      "loss is:  2.696309\n",
      "loss is:  2.69502\n",
      "loss is:  2.6937337\n",
      "loss is:  2.6924505\n",
      "loss is:  2.69117\n",
      "loss is:  2.6898925\n",
      "loss is:  2.6886175\n",
      "loss is:  2.687346\n",
      "loss is:  2.6860766\n",
      "loss is:  2.6848104\n",
      "loss is:  2.6835473\n",
      "loss is:  2.682286\n",
      "loss is:  2.6810284\n",
      "loss is:  2.679773\n",
      "loss is:  2.6785207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  2.677271\n",
      "loss is:  2.6760242\n",
      "loss is:  2.6747797\n",
      "loss is:  2.6735377\n",
      "loss is:  2.6722987\n",
      "loss is:  2.6710622\n",
      "loss is:  2.6698284\n",
      "loss is:  2.6685972\n",
      "loss is:  2.6673687\n",
      "loss is:  2.6661427\n",
      "loss is:  2.6649191\n",
      "loss is:  2.6636982\n",
      "loss is:  2.6624799\n",
      "loss is:  2.661264\n",
      "loss is:  2.6600504\n",
      "loss is:  2.6588395\n",
      "loss is:  2.6576312\n",
      "loss is:  2.656425\n",
      "loss is:  2.6552215\n",
      "loss is:  2.6540205\n",
      "loss is:  2.6528218\n",
      "loss is:  2.6516256\n",
      "loss is:  2.6504314\n",
      "loss is:  2.6492403\n",
      "loss is:  2.6480508\n",
      "loss is:  2.646864\n",
      "loss is:  2.6456797\n",
      "loss is:  2.6444972\n",
      "loss is:  2.6433172\n",
      "loss is:  2.6421397\n",
      "loss is:  2.6409643\n",
      "loss is:  2.6397913\n",
      "loss is:  2.6386204\n",
      "loss is:  2.637452\n",
      "loss is:  2.6362855\n",
      "loss is:  2.6351213\n",
      "loss is:  2.6339593\n",
      "loss is:  2.6327996\n",
      "loss is:  2.6316419\n",
      "loss is:  2.6304862\n",
      "loss is:  2.629333\n",
      "loss is:  2.628182\n",
      "loss is:  2.627033\n",
      "loss is:  2.6258862\n",
      "loss is:  2.6247408\n",
      "loss is:  2.6235983\n",
      "loss is:  2.6224575\n",
      "loss is:  2.6213188\n",
      "loss is:  2.6201823\n",
      "loss is:  2.6190479\n",
      "loss is:  2.6179156\n",
      "loss is:  2.6167848\n",
      "loss is:  2.6156561\n",
      "loss is:  2.6145298\n",
      "loss is:  2.6134052\n",
      "loss is:  2.6122825\n",
      "loss is:  2.6111622\n",
      "loss is:  2.6100435\n",
      "loss is:  2.6089265\n",
      "loss is:  2.607812\n",
      "loss is:  2.6066988\n",
      "loss is:  2.6055882\n",
      "loss is:  2.6044788\n",
      "loss is:  2.6033714\n",
      "loss is:  2.6022663\n",
      "loss is:  2.6011627\n",
      "loss is:  2.600061\n",
      "loss is:  2.5989614\n",
      "loss is:  2.597863\n",
      "loss is:  2.5967672\n",
      "loss is:  2.5956728\n",
      "loss is:  2.5945802\n",
      "loss is:  2.5934892\n",
      "loss is:  2.5924003\n",
      "loss is:  2.5913131\n",
      "loss is:  2.5902276\n",
      "loss is:  2.589144\n",
      "loss is:  2.5880618\n",
      "loss is:  2.586982\n",
      "loss is:  2.5859034\n",
      "loss is:  2.5848265\n",
      "loss is:  2.5837512\n",
      "loss is:  2.582678\n",
      "loss is:  2.5816061\n",
      "loss is:  2.5805364\n",
      "loss is:  2.5794678\n",
      "loss is:  2.5784009\n",
      "loss is:  2.577336\n",
      "loss is:  2.5762727\n",
      "loss is:  2.5752108\n",
      "loss is:  2.5741506\n",
      "loss is:  2.5730925\n",
      "loss is:  2.5720356\n",
      "loss is:  2.5709803\n",
      "loss is:  2.5699265\n",
      "loss is:  2.5688744\n",
      "loss is:  2.567824\n",
      "loss is:  2.5667748\n",
      "loss is:  2.5657275\n",
      "loss is:  2.5646818\n",
      "loss is:  2.5636373\n",
      "loss is:  2.562595\n",
      "loss is:  2.5615532\n",
      "loss is:  2.5605137\n",
      "loss is:  2.5594757\n",
      "loss is:  2.558439\n",
      "loss is:  2.557404\n",
      "loss is:  2.5563703\n",
      "loss is:  2.5553384\n",
      "loss is:  2.5543077\n",
      "loss is:  2.5532784\n",
      "loss is:  2.5522506\n",
      "loss is:  2.5512245\n",
      "loss is:  2.5501997\n",
      "loss is:  2.5491765\n",
      "loss is:  2.5481548\n",
      "loss is:  2.5471344\n",
      "loss is:  2.546115\n",
      "loss is:  2.5450976\n",
      "loss is:  2.5440812\n",
      "loss is:  2.5430665\n",
      "loss is:  2.5420532\n",
      "loss is:  2.5410416\n",
      "loss is:  2.540031\n",
      "loss is:  2.5390217\n",
      "loss is:  2.5380142\n",
      "loss is:  2.5370078\n",
      "loss is:  2.5360029\n",
      "loss is:  2.5349991\n",
      "loss is:  2.5339973\n",
      "loss is:  2.5329964\n",
      "loss is:  2.5319967\n",
      "loss is:  2.5309987\n",
      "loss is:  2.5300019\n",
      "loss is:  2.5290065\n",
      "loss is:  2.528012\n",
      "loss is:  2.5270197\n",
      "loss is:  2.526028\n",
      "loss is:  2.5250378\n",
      "loss is:  2.524049\n",
      "loss is:  2.5230615\n",
      "loss is:  2.5220757\n",
      "loss is:  2.5210903\n",
      "loss is:  2.520107\n",
      "loss is:  2.5191243\n",
      "loss is:  2.5181434\n",
      "loss is:  2.5171638\n",
      "loss is:  2.5161855\n",
      "loss is:  2.5152082\n",
      "loss is:  2.5142324\n",
      "loss is:  2.5132575\n",
      "loss is:  2.5122843\n",
      "loss is:  2.5113122\n",
      "loss is:  2.5103414\n",
      "loss is:  2.5093718\n",
      "loss is:  2.5084035\n",
      "loss is:  2.5074363\n",
      "loss is:  2.5064707\n",
      "loss is:  2.505506\n",
      "loss is:  2.5045424\n",
      "loss is:  2.5035803\n",
      "loss is:  2.5026193\n",
      "loss is:  2.5016599\n",
      "loss is:  2.5007014\n",
      "loss is:  2.4997442\n",
      "loss is:  2.4987879\n",
      "loss is:  2.497833\n",
      "loss is:  2.4968796\n",
      "loss is:  2.4959273\n",
      "loss is:  2.4949758\n",
      "loss is:  2.494026\n",
      "loss is:  2.493077\n",
      "loss is:  2.4921296\n",
      "loss is:  2.4911833\n",
      "loss is:  2.4902377\n",
      "loss is:  2.4892936\n",
      "loss is:  2.4883506\n",
      "loss is:  2.487409\n",
      "loss is:  2.4864683\n",
      "loss is:  2.485529\n",
      "loss is:  2.4845912\n",
      "loss is:  2.483654\n",
      "loss is:  2.4827182\n",
      "loss is:  2.4817834\n",
      "loss is:  2.48085\n",
      "loss is:  2.4799175\n",
      "loss is:  2.4789863\n",
      "loss is:  2.4780564\n",
      "loss is:  2.4771273\n",
      "loss is:  2.4761996\n",
      "loss is:  2.475273\n",
      "loss is:  2.4743476\n",
      "loss is:  2.473423\n",
      "loss is:  2.4724998\n",
      "loss is:  2.4715781\n",
      "loss is:  2.4706573\n",
      "loss is:  2.4697373\n",
      "loss is:  2.468819\n",
      "loss is:  2.4679015\n",
      "loss is:  2.466985\n",
      "loss is:  2.46607\n",
      "loss is:  2.4651556\n",
      "loss is:  2.464243\n",
      "loss is:  2.4633307\n",
      "loss is:  2.46242\n",
      "loss is:  2.4615107\n",
      "loss is:  2.4606023\n",
      "loss is:  2.4596944\n",
      "loss is:  2.4587886\n",
      "loss is:  2.4578836\n",
      "loss is:  2.4569795\n",
      "loss is:  2.4560766\n",
      "loss is:  2.4551747\n",
      "loss is:  2.4542742\n",
      "loss is:  2.4533746\n",
      "loss is:  2.452476\n",
      "loss is:  2.451579\n",
      "loss is:  2.4506826\n",
      "loss is:  2.4497876\n",
      "loss is:  2.4488935\n",
      "loss is:  2.4480004\n",
      "loss is:  2.4471087\n",
      "loss is:  2.4462178\n",
      "loss is:  2.4453282\n",
      "loss is:  2.4444401\n",
      "loss is:  2.4435527\n",
      "loss is:  2.442666\n",
      "loss is:  2.441781\n",
      "loss is:  2.4408967\n",
      "loss is:  2.440014\n",
      "loss is:  2.439132\n",
      "loss is:  2.438251\n",
      "loss is:  2.4373715\n",
      "loss is:  2.436493\n",
      "loss is:  2.4356155\n",
      "loss is:  2.4347389\n",
      "loss is:  2.4338636\n",
      "loss is:  2.4329894\n",
      "loss is:  2.432116\n",
      "loss is:  2.431244\n",
      "loss is:  2.4303732\n",
      "loss is:  2.4295032\n",
      "loss is:  2.4286344\n",
      "loss is:  2.427767\n",
      "loss is:  2.4269\n",
      "loss is:  2.4260347\n",
      "loss is:  2.4251702\n",
      "loss is:  2.4243069\n",
      "loss is:  2.4234445\n",
      "loss is:  2.4225836\n",
      "loss is:  2.4217234\n",
      "loss is:  2.4208643\n",
      "loss is:  2.4200065\n",
      "loss is:  2.41915\n",
      "loss is:  2.418294\n",
      "loss is:  2.4174395\n",
      "loss is:  2.416586\n",
      "loss is:  2.4157336\n",
      "loss is:  2.4148822\n",
      "loss is:  2.414032\n",
      "loss is:  2.4131832\n",
      "loss is:  2.412335\n",
      "loss is:  2.411488\n",
      "loss is:  2.410642\n",
      "loss is:  2.4097974\n",
      "loss is:  2.4089534\n",
      "loss is:  2.4081109\n",
      "loss is:  2.4072697\n",
      "loss is:  2.406429\n",
      "loss is:  2.4055898\n",
      "loss is:  2.4047513\n",
      "loss is:  2.4039145\n",
      "loss is:  2.4030783\n",
      "loss is:  2.4022436\n",
      "loss is:  2.4014096\n",
      "loss is:  2.400577\n",
      "loss is:  2.399745\n",
      "loss is:  2.398915\n",
      "loss is:  2.398085\n",
      "loss is:  2.397257\n",
      "loss is:  2.3964295\n",
      "loss is:  2.3956037\n",
      "loss is:  2.3947785\n",
      "loss is:  2.3939548\n",
      "loss is:  2.393132\n",
      "loss is:  2.3923097\n",
      "loss is:  2.3914895\n",
      "loss is:  2.3906698\n",
      "loss is:  2.3898516\n",
      "loss is:  2.3890343\n",
      "loss is:  2.388218\n",
      "loss is:  2.3874028\n",
      "loss is:  2.3865888\n",
      "loss is:  2.385776\n",
      "loss is:  2.384964\n",
      "loss is:  2.3841536\n",
      "loss is:  2.3833442\n",
      "loss is:  2.3825355\n",
      "loss is:  2.3817284\n",
      "loss is:  2.380922\n",
      "loss is:  2.3801167\n",
      "loss is:  2.379313\n",
      "loss is:  2.37851\n",
      "loss is:  2.3777082\n",
      "loss is:  2.3769078\n",
      "loss is:  2.3761082\n",
      "loss is:  2.3753097\n",
      "loss is:  2.3745124\n",
      "loss is:  2.3737166\n",
      "loss is:  2.3729212\n",
      "loss is:  2.3721275\n",
      "loss is:  2.3713348\n",
      "loss is:  2.3705432\n",
      "loss is:  2.3697526\n",
      "loss is:  2.3689632\n",
      "loss is:  2.3681748\n",
      "loss is:  2.3673878\n",
      "loss is:  2.3666017\n",
      "loss is:  2.3658168\n",
      "loss is:  2.3650334\n",
      "loss is:  2.364251\n",
      "loss is:  2.3634691\n",
      "loss is:  2.3626888\n",
      "loss is:  2.3619094\n",
      "loss is:  2.3611317\n",
      "loss is:  2.3603547\n",
      "loss is:  2.359579\n",
      "loss is:  2.3588042\n",
      "loss is:  2.358031\n",
      "loss is:  2.3572588\n",
      "loss is:  2.3564873\n",
      "loss is:  2.3557177\n",
      "loss is:  2.3549485\n",
      "loss is:  2.3541808\n",
      "loss is:  2.353414\n",
      "loss is:  2.3526487\n",
      "loss is:  2.3518844\n",
      "loss is:  2.3511214\n",
      "loss is:  2.3503594\n",
      "loss is:  2.3495984\n",
      "loss is:  2.3488388\n",
      "loss is:  2.3480802\n",
      "loss is:  2.3473232\n",
      "loss is:  2.346567\n",
      "loss is:  2.345812\n",
      "loss is:  2.3450582\n",
      "loss is:  2.3443053\n",
      "loss is:  2.343554\n",
      "loss is:  2.3428035\n",
      "loss is:  2.3420541\n",
      "loss is:  2.3413064\n",
      "loss is:  2.3405595\n",
      "loss is:  2.339814\n",
      "loss is:  2.3390694\n",
      "loss is:  2.3383257\n",
      "loss is:  2.3375843\n",
      "loss is:  2.3368428\n",
      "loss is:  2.3361032\n",
      "loss is:  2.3353643\n",
      "loss is:  2.3346272\n",
      "loss is:  2.333891\n",
      "loss is:  2.3331559\n",
      "loss is:  2.332422\n",
      "loss is:  2.3316891\n",
      "loss is:  2.3309577\n",
      "loss is:  2.3302274\n",
      "loss is:  2.3294983\n",
      "loss is:  2.3287702\n",
      "loss is:  2.3280435\n",
      "loss is:  2.3273182\n",
      "loss is:  2.3265936\n",
      "loss is:  2.3258705\n",
      "loss is:  2.3251488\n",
      "loss is:  2.3244278\n",
      "loss is:  2.3237083\n",
      "loss is:  2.32299\n",
      "loss is:  2.3222725\n",
      "loss is:  2.3215568\n",
      "loss is:  2.320842\n",
      "loss is:  2.3201284\n",
      "loss is:  2.319416\n",
      "loss is:  2.3187053\n",
      "loss is:  2.317995\n",
      "loss is:  2.3172863\n",
      "loss is:  2.3165789\n",
      "loss is:  2.3158722\n",
      "loss is:  2.3151674\n",
      "loss is:  2.3144636\n",
      "loss is:  2.313761\n",
      "loss is:  2.3130593\n",
      "loss is:  2.312359\n",
      "loss is:  2.31166\n",
      "loss is:  2.3109624\n",
      "loss is:  2.310266\n",
      "loss is:  2.30957\n",
      "loss is:  2.3088765\n",
      "loss is:  2.3081834\n",
      "loss is:  2.3074915\n",
      "loss is:  2.3068013\n",
      "loss is:  2.3061118\n",
      "loss is:  2.3054237\n",
      "loss is:  2.304737\n",
      "loss is:  2.3040516\n",
      "loss is:  2.3033671\n",
      "loss is:  2.3026838\n",
      "loss is:  2.3020022\n",
      "loss is:  2.3013215\n",
      "loss is:  2.3006425\n",
      "loss is:  2.299964\n",
      "loss is:  2.2992873\n",
      "loss is:  2.2986114\n",
      "loss is:  2.297937\n",
      "loss is:  2.2972636\n",
      "loss is:  2.2965918\n",
      "loss is:  2.295921\n",
      "loss is:  2.2952514\n",
      "loss is:  2.294583\n",
      "loss is:  2.2939162\n",
      "loss is:  2.2932503\n",
      "loss is:  2.2925858\n",
      "loss is:  2.2919226\n",
      "loss is:  2.2912605\n",
      "loss is:  2.2905996\n",
      "loss is:  2.2899404\n",
      "loss is:  2.289282\n",
      "loss is:  2.2886248\n",
      "loss is:  2.2879689\n",
      "loss is:  2.2873147\n",
      "loss is:  2.2866611\n",
      "loss is:  2.286009\n",
      "loss is:  2.2853582\n",
      "loss is:  2.284709\n",
      "loss is:  2.2840605\n",
      "loss is:  2.2834132\n",
      "loss is:  2.2827675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  2.2821229\n",
      "loss is:  2.2814798\n",
      "loss is:  2.2808378\n",
      "loss is:  2.280197\n",
      "loss is:  2.2795572\n",
      "loss is:  2.2789192\n",
      "loss is:  2.278282\n",
      "loss is:  2.2776463\n",
      "loss is:  2.2770116\n",
      "loss is:  2.2763786\n",
      "loss is:  2.2757466\n",
      "loss is:  2.2751157\n",
      "loss is:  2.2744865\n",
      "loss is:  2.2738583\n",
      "loss is:  2.2732313\n",
      "loss is:  2.2726054\n",
      "loss is:  2.2719812\n",
      "loss is:  2.271358\n",
      "loss is:  2.2707362\n",
      "loss is:  2.2701154\n",
      "loss is:  2.269496\n",
      "loss is:  2.2688782\n",
      "loss is:  2.268261\n",
      "loss is:  2.2676456\n",
      "loss is:  2.2670314\n",
      "loss is:  2.2664185\n",
      "loss is:  2.2658064\n",
      "loss is:  2.265196\n",
      "loss is:  2.2645867\n",
      "loss is:  2.2639787\n",
      "loss is:  2.2633722\n",
      "loss is:  2.2627666\n",
      "loss is:  2.2621622\n",
      "loss is:  2.2615592\n",
      "loss is:  2.260958\n",
      "loss is:  2.2603574\n",
      "loss is:  2.2597582\n",
      "loss is:  2.2591603\n",
      "loss is:  2.2585638\n",
      "loss is:  2.2579684\n",
      "loss is:  2.2573745\n",
      "loss is:  2.2567813\n",
      "loss is:  2.25619\n",
      "loss is:  2.2555997\n",
      "loss is:  2.2550108\n",
      "loss is:  2.254423\n",
      "loss is:  2.2538366\n",
      "loss is:  2.2532513\n",
      "loss is:  2.2526674\n",
      "loss is:  2.2520845\n",
      "loss is:  2.2515032\n",
      "loss is:  2.2509234\n",
      "loss is:  2.250344\n",
      "loss is:  2.2497663\n",
      "loss is:  2.2491899\n",
      "loss is:  2.2486148\n",
      "loss is:  2.2480412\n",
      "loss is:  2.2474685\n",
      "loss is:  2.246897\n",
      "loss is:  2.2463272\n",
      "loss is:  2.2457583\n",
      "loss is:  2.2451909\n",
      "loss is:  2.2446246\n",
      "loss is:  2.2440596\n",
      "loss is:  2.2434957\n",
      "loss is:  2.2429333\n",
      "loss is:  2.2423718\n",
      "loss is:  2.241812\n",
      "loss is:  2.2412531\n",
      "loss is:  2.2406957\n",
      "loss is:  2.2401395\n",
      "loss is:  2.2395847\n",
      "loss is:  2.2390308\n",
      "loss is:  2.2384782\n",
      "loss is:  2.2379272\n",
      "loss is:  2.2373774\n",
      "loss is:  2.2368286\n",
      "loss is:  2.236281\n",
      "loss is:  2.235735\n",
      "loss is:  2.2351902\n",
      "loss is:  2.234646\n",
      "loss is:  2.234104\n",
      "loss is:  2.2335622\n",
      "loss is:  2.2330222\n",
      "loss is:  2.2324839\n",
      "loss is:  2.2319465\n",
      "loss is:  2.2314103\n",
      "loss is:  2.230875\n",
      "loss is:  2.2303414\n",
      "loss is:  2.229809\n",
      "loss is:  2.2292778\n",
      "loss is:  2.2287476\n",
      "loss is:  2.228219\n",
      "loss is:  2.2276914\n",
      "loss is:  2.227165\n",
      "loss is:  2.22664\n",
      "loss is:  2.2261162\n",
      "loss is:  2.2255936\n",
      "loss is:  2.2250724\n",
      "loss is:  2.2245522\n",
      "loss is:  2.224033\n",
      "loss is:  2.2235155\n",
      "loss is:  2.222999\n",
      "loss is:  2.2224836\n",
      "loss is:  2.2219698\n",
      "loss is:  2.2214575\n",
      "loss is:  2.2209456\n",
      "loss is:  2.2204351\n",
      "loss is:  2.219926\n",
      "loss is:  2.219418\n",
      "loss is:  2.2189116\n",
      "loss is:  2.2184062\n",
      "loss is:  2.217902\n",
      "loss is:  2.2173991\n",
      "loss is:  2.2168975\n",
      "loss is:  2.2163966\n",
      "loss is:  2.2158973\n",
      "loss is:  2.2153993\n",
      "loss is:  2.2149022\n",
      "loss is:  2.2144065\n",
      "loss is:  2.213912\n",
      "loss is:  2.2134187\n",
      "loss is:  2.2129269\n",
      "loss is:  2.212436\n",
      "loss is:  2.2119458\n",
      "loss is:  2.2114575\n",
      "loss is:  2.2109702\n",
      "loss is:  2.2104843\n",
      "loss is:  2.2099993\n",
      "loss is:  2.2095156\n",
      "loss is:  2.209033\n",
      "loss is:  2.2085514\n",
      "loss is:  2.2080715\n",
      "loss is:  2.2075925\n",
      "loss is:  2.2071147\n",
      "loss is:  2.206638\n",
      "loss is:  2.2061627\n",
      "loss is:  2.2056887\n",
      "loss is:  2.2052155\n",
      "loss is:  2.2047436\n",
      "loss is:  2.2042727\n",
      "loss is:  2.2038033\n",
      "loss is:  2.2033348\n",
      "loss is:  2.202868\n",
      "loss is:  2.2024019\n",
      "loss is:  2.201937\n",
      "loss is:  2.2014732\n",
      "loss is:  2.2010107\n",
      "loss is:  2.2005496\n",
      "loss is:  2.2000892\n",
      "loss is:  2.1996303\n",
      "loss is:  2.1991723\n",
      "loss is:  2.1987154\n",
      "loss is:  2.19826\n",
      "loss is:  2.197806\n",
      "loss is:  2.1973524\n",
      "loss is:  2.1969001\n",
      "loss is:  2.1964493\n",
      "loss is:  2.1959994\n",
      "loss is:  2.1955507\n",
      "loss is:  2.1951034\n",
      "loss is:  2.1946566\n",
      "loss is:  2.1942115\n",
      "loss is:  2.1937675\n",
      "loss is:  2.1933246\n",
      "loss is:  2.1928823\n",
      "loss is:  2.1924422\n",
      "loss is:  2.1920023\n",
      "loss is:  2.1915634\n",
      "loss is:  2.1911263\n",
      "loss is:  2.19069\n",
      "loss is:  2.190255\n",
      "loss is:  2.1898208\n",
      "loss is:  2.189388\n",
      "loss is:  2.1889563\n",
      "loss is:  2.1885254\n",
      "loss is:  2.188096\n",
      "loss is:  2.1876674\n",
      "loss is:  2.1872401\n",
      "loss is:  2.1868138\n",
      "loss is:  2.1863887\n",
      "loss is:  2.1859648\n",
      "loss is:  2.1855419\n",
      "loss is:  2.18512\n",
      "loss is:  2.1846993\n",
      "loss is:  2.1842794\n",
      "loss is:  2.1838608\n",
      "loss is:  2.1834435\n",
      "loss is:  2.183027\n",
      "loss is:  2.1826115\n",
      "loss is:  2.1821976\n",
      "loss is:  2.181784\n",
      "loss is:  2.1813722\n",
      "loss is:  2.1809611\n",
      "loss is:  2.1805508\n",
      "loss is:  2.180142\n",
      "loss is:  2.1797342\n",
      "loss is:  2.1793275\n",
      "loss is:  2.1789215\n",
      "loss is:  2.1785173\n",
      "loss is:  2.1781135\n",
      "loss is:  2.177711\n",
      "loss is:  2.1773095\n",
      "loss is:  2.176909\n",
      "loss is:  2.1765096\n",
      "loss is:  2.176111\n",
      "loss is:  2.175714\n",
      "loss is:  2.1753175\n",
      "loss is:  2.1749225\n",
      "loss is:  2.1745284\n",
      "loss is:  2.174135\n",
      "loss is:  2.1737428\n",
      "loss is:  2.1733518\n",
      "loss is:  2.1729617\n",
      "loss is:  2.1725726\n",
      "loss is:  2.1721847\n",
      "loss is:  2.1717978\n",
      "loss is:  2.1714115\n",
      "loss is:  2.1710265\n",
      "loss is:  2.1706429\n",
      "loss is:  2.1702597\n",
      "loss is:  2.169878\n",
      "loss is:  2.1694968\n",
      "loss is:  2.169117\n",
      "loss is:  2.168738\n",
      "loss is:  2.1683598\n",
      "loss is:  2.1679833\n",
      "loss is:  2.1676073\n",
      "loss is:  2.1672323\n",
      "loss is:  2.1668584\n",
      "loss is:  2.166485\n",
      "loss is:  2.1661131\n",
      "loss is:  2.1657424\n",
      "loss is:  2.1653721\n",
      "loss is:  2.1650033\n",
      "loss is:  2.164635\n",
      "loss is:  2.164268\n",
      "loss is:  2.1639018\n",
      "loss is:  2.1635368\n",
      "loss is:  2.1631725\n",
      "loss is:  2.1628091\n",
      "loss is:  2.162447\n",
      "loss is:  2.1620853\n",
      "loss is:  2.1617255\n",
      "loss is:  2.161366\n",
      "loss is:  2.1610074\n",
      "loss is:  2.16065\n",
      "loss is:  2.1602933\n",
      "loss is:  2.1599379\n",
      "loss is:  2.1595829\n",
      "loss is:  2.1592293\n",
      "loss is:  2.1588762\n",
      "loss is:  2.1585245\n",
      "loss is:  2.1581736\n",
      "loss is:  2.1578236\n",
      "loss is:  2.1574745\n",
      "loss is:  2.1571262\n",
      "loss is:  2.1567793\n",
      "loss is:  2.1564329\n",
      "loss is:  2.1560872\n",
      "loss is:  2.1557431\n",
      "loss is:  2.155399\n",
      "loss is:  2.1550565\n",
      "loss is:  2.1547148\n",
      "loss is:  2.154374\n",
      "loss is:  2.154034\n",
      "loss is:  2.1536946\n",
      "loss is:  2.1533568\n",
      "loss is:  2.1530194\n",
      "loss is:  2.1526833\n",
      "loss is:  2.1523473\n",
      "loss is:  2.1520128\n",
      "loss is:  2.1516793\n",
      "loss is:  2.1513464\n",
      "loss is:  2.1510146\n",
      "loss is:  2.1506832\n",
      "loss is:  2.150353\n",
      "loss is:  2.1500237\n",
      "loss is:  2.1496954\n",
      "loss is:  2.1493676\n",
      "loss is:  2.1490412\n",
      "loss is:  2.148715\n",
      "loss is:  2.14839\n",
      "loss is:  2.148066\n",
      "loss is:  2.1477427\n",
      "loss is:  2.1474204\n",
      "loss is:  2.1470988\n",
      "loss is:  2.1467779\n",
      "loss is:  2.1464581\n",
      "loss is:  2.1461391\n",
      "loss is:  2.1458209\n",
      "loss is:  2.145504\n",
      "loss is:  2.145187\n",
      "loss is:  2.1448712\n",
      "loss is:  2.1445565\n",
      "loss is:  2.1442423\n",
      "loss is:  2.143929\n",
      "loss is:  2.143617\n",
      "loss is:  2.143305\n",
      "loss is:  2.1429946\n",
      "loss is:  2.142685\n",
      "loss is:  2.1423755\n",
      "loss is:  2.1420674\n",
      "loss is:  2.1417596\n",
      "loss is:  2.141453\n",
      "loss is:  2.1411474\n",
      "loss is:  2.1408422\n",
      "loss is:  2.1405377\n",
      "loss is:  2.1402345\n",
      "loss is:  2.139932\n",
      "loss is:  2.13963\n",
      "loss is:  2.139329\n",
      "loss is:  2.1390285\n",
      "loss is:  2.1387293\n",
      "loss is:  2.1384306\n",
      "loss is:  2.1381328\n",
      "loss is:  2.1378353\n",
      "loss is:  2.1375391\n",
      "loss is:  2.1372435\n",
      "loss is:  2.136948\n",
      "loss is:  2.1366541\n",
      "loss is:  2.1363614\n",
      "loss is:  2.1360688\n",
      "loss is:  2.135777\n",
      "loss is:  2.135486\n",
      "loss is:  2.135196\n",
      "loss is:  2.134906\n",
      "loss is:  2.1346176\n",
      "loss is:  2.1343298\n",
      "loss is:  2.1340423\n",
      "loss is:  2.1337557\n",
      "loss is:  2.13347\n",
      "loss is:  2.1331847\n",
      "loss is:  2.132901\n",
      "loss is:  2.1326175\n",
      "loss is:  2.1323347\n",
      "loss is:  2.1320524\n",
      "loss is:  2.1317713\n",
      "loss is:  2.1314905\n",
      "loss is:  2.1312108\n",
      "loss is:  2.1309319\n",
      "loss is:  2.1306531\n",
      "loss is:  2.1303756\n",
      "loss is:  2.1300983\n",
      "loss is:  2.1298225\n",
      "loss is:  2.1295466\n",
      "loss is:  2.129272\n",
      "loss is:  2.128998\n",
      "loss is:  2.1287246\n",
      "loss is:  2.128452\n",
      "loss is:  2.12818\n",
      "loss is:  2.1279085\n",
      "loss is:  2.1276379\n",
      "loss is:  2.1273682\n",
      "loss is:  2.127099\n",
      "loss is:  2.1268306\n",
      "loss is:  2.1265624\n",
      "loss is:  2.1262953\n",
      "loss is:  2.126029\n",
      "loss is:  2.1257632\n",
      "loss is:  2.1254983\n",
      "loss is:  2.1252337\n",
      "loss is:  2.1249702\n",
      "loss is:  2.1247072\n",
      "loss is:  2.1244447\n",
      "loss is:  2.124183\n",
      "loss is:  2.1239219\n",
      "loss is:  2.1236615\n",
      "loss is:  2.1234019\n",
      "loss is:  2.1231427\n",
      "loss is:  2.1228845\n",
      "loss is:  2.1226268\n",
      "loss is:  2.1223695\n",
      "loss is:  2.1221132\n",
      "loss is:  2.1218576\n",
      "loss is:  2.1216023\n",
      "loss is:  2.1213481\n",
      "loss is:  2.1210942\n",
      "loss is:  2.120841\n",
      "loss is:  2.1205885\n",
      "loss is:  2.1203368\n",
      "loss is:  2.1200855\n",
      "loss is:  2.1198347\n",
      "loss is:  2.1195848\n",
      "loss is:  2.1193357\n",
      "loss is:  2.1190867\n",
      "loss is:  2.1188385\n",
      "loss is:  2.1185913\n",
      "loss is:  2.118344\n",
      "loss is:  2.118098\n",
      "loss is:  2.1178527\n",
      "loss is:  2.1176074\n",
      "loss is:  2.1173632\n",
      "loss is:  2.1171193\n",
      "loss is:  2.1168764\n",
      "loss is:  2.116634\n",
      "loss is:  2.116392\n",
      "loss is:  2.1161504\n",
      "loss is:  2.1159096\n",
      "loss is:  2.11567\n",
      "loss is:  2.1154304\n",
      "loss is:  2.1151912\n",
      "loss is:  2.1149533\n",
      "loss is:  2.1147156\n",
      "loss is:  2.1144783\n",
      "loss is:  2.1142418\n",
      "loss is:  2.1140056\n",
      "loss is:  2.1137705\n",
      "loss is:  2.1135356\n",
      "loss is:  2.1133013\n",
      "loss is:  2.1130676\n",
      "loss is:  2.112835\n",
      "loss is:  2.1126025\n",
      "loss is:  2.1123703\n",
      "loss is:  2.112139\n",
      "loss is:  2.1119087\n",
      "loss is:  2.1116781\n",
      "loss is:  2.1114488\n",
      "loss is:  2.1112196\n",
      "loss is:  2.1109912\n",
      "loss is:  2.1107633\n",
      "loss is:  2.1105359\n",
      "loss is:  2.1103091\n",
      "loss is:  2.1100829\n",
      "loss is:  2.1098573\n",
      "loss is:  2.109632\n",
      "loss is:  2.1094074\n",
      "loss is:  2.1091835\n",
      "loss is:  2.1089602\n",
      "loss is:  2.1087375\n",
      "loss is:  2.1085148\n",
      "loss is:  2.108293\n",
      "loss is:  2.1080716\n",
      "loss is:  2.107851\n",
      "loss is:  2.1076307\n",
      "loss is:  2.1074111\n",
      "loss is:  2.107192\n",
      "loss is:  2.1069734\n",
      "loss is:  2.1067553\n",
      "loss is:  2.106538\n",
      "loss is:  2.1063206\n",
      "loss is:  2.1061041\n",
      "loss is:  2.1058884\n",
      "loss is:  2.1056728\n",
      "loss is:  2.1054583\n",
      "loss is:  2.1052437\n",
      "loss is:  2.1050298\n",
      "loss is:  2.1048164\n",
      "loss is:  2.1046035\n",
      "loss is:  2.1043913\n",
      "loss is:  2.1041796\n",
      "loss is:  2.1039681\n",
      "loss is:  2.1037571\n",
      "loss is:  2.103547\n",
      "loss is:  2.103337\n",
      "loss is:  2.1031277\n",
      "loss is:  2.102919\n",
      "loss is:  2.1027107\n",
      "loss is:  2.1025026\n",
      "loss is:  2.1022959\n",
      "loss is:  2.1020887\n",
      "loss is:  2.1018825\n",
      "loss is:  2.1016767\n",
      "loss is:  2.1014714\n",
      "loss is:  2.1012664\n",
      "loss is:  2.101062\n",
      "loss is:  2.1008582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  2.100655\n",
      "loss is:  2.100452\n",
      "loss is:  2.1002495\n",
      "loss is:  2.1000473\n",
      "loss is:  2.0998461\n",
      "loss is:  2.0996451\n",
      "loss is:  2.0994446\n",
      "loss is:  2.0992446\n",
      "loss is:  2.0990448\n",
      "loss is:  2.098846\n",
      "loss is:  2.098647\n",
      "loss is:  2.098449\n",
      "loss is:  2.0982513\n",
      "loss is:  2.0980542\n",
      "loss is:  2.097857\n",
      "loss is:  2.0976613\n",
      "loss is:  2.097465\n",
      "loss is:  2.0972698\n",
      "loss is:  2.097075\n",
      "loss is:  2.0968802\n",
      "loss is:  2.0966861\n",
      "loss is:  2.0964928\n",
      "loss is:  2.0962994\n",
      "loss is:  2.0961068\n",
      "loss is:  2.0959146\n",
      "loss is:  2.095723\n",
      "loss is:  2.0955315\n",
      "loss is:  2.0953405\n",
      "loss is:  2.0951502\n",
      "loss is:  2.0949602\n",
      "loss is:  2.0947702\n",
      "loss is:  2.0945814\n",
      "loss is:  2.0943928\n",
      "loss is:  2.0942044\n",
      "loss is:  2.0940166\n",
      "loss is:  2.093829\n",
      "loss is:  2.0936422\n",
      "loss is:  2.0934553\n",
      "loss is:  2.0932696\n",
      "loss is:  2.0930839\n",
      "loss is:  2.0928986\n",
      "loss is:  2.0927136\n",
      "loss is:  2.0925288\n",
      "loss is:  2.092345\n",
      "loss is:  2.0921614\n",
      "loss is:  2.0919783\n",
      "loss is:  2.0917957\n",
      "loss is:  2.091613\n",
      "loss is:  2.0914314\n",
      "loss is:  2.0912497\n",
      "loss is:  2.0910687\n",
      "loss is:  2.0908878\n",
      "loss is:  2.0907078\n",
      "loss is:  2.090528\n",
      "loss is:  2.0903482\n",
      "loss is:  2.0901694\n",
      "loss is:  2.0899906\n",
      "loss is:  2.0898123\n",
      "loss is:  2.0896347\n",
      "loss is:  2.0894573\n",
      "loss is:  2.0892801\n",
      "loss is:  2.0891035\n",
      "loss is:  2.088927\n",
      "loss is:  2.0887513\n",
      "loss is:  2.0885756\n",
      "loss is:  2.0884006\n",
      "loss is:  2.088226\n",
      "loss is:  2.0880516\n",
      "loss is:  2.0878778\n",
      "loss is:  2.0877042\n",
      "loss is:  2.087531\n",
      "loss is:  2.0873585\n",
      "loss is:  2.0871859\n",
      "loss is:  2.0870137\n",
      "loss is:  2.0868425\n",
      "loss is:  2.086671\n",
      "loss is:  2.0865004\n",
      "loss is:  2.08633\n",
      "loss is:  2.0861597\n",
      "loss is:  2.0859904\n",
      "loss is:  2.085821\n",
      "loss is:  2.0856516\n",
      "loss is:  2.0854833\n",
      "loss is:  2.085315\n",
      "loss is:  2.0851471\n",
      "loss is:  2.0849795\n",
      "loss is:  2.0848124\n",
      "loss is:  2.0846457\n",
      "loss is:  2.0844796\n",
      "loss is:  2.0843134\n",
      "loss is:  2.0841477\n",
      "loss is:  2.0839825\n",
      "loss is:  2.0838175\n",
      "loss is:  2.0836527\n",
      "loss is:  2.0834887\n",
      "loss is:  2.083325\n",
      "loss is:  2.0831616\n",
      "loss is:  2.082998\n",
      "loss is:  2.0828352\n",
      "loss is:  2.0826728\n",
      "loss is:  2.0825107\n",
      "loss is:  2.082349\n",
      "loss is:  2.0821877\n",
      "loss is:  2.0820265\n",
      "loss is:  2.0818658\n",
      "loss is:  2.0817056\n",
      "loss is:  2.0815456\n",
      "loss is:  2.0813859\n",
      "loss is:  2.0812263\n",
      "loss is:  2.0810676\n",
      "loss is:  2.0809088\n",
      "loss is:  2.0807507\n",
      "loss is:  2.0805926\n",
      "loss is:  2.0804348\n",
      "loss is:  2.080278\n",
      "loss is:  2.0801208\n",
      "loss is:  2.0799642\n",
      "loss is:  2.0798078\n",
      "loss is:  2.0796518\n",
      "loss is:  2.0794961\n",
      "loss is:  2.079341\n",
      "loss is:  2.0791857\n",
      "loss is:  2.0790312\n",
      "loss is:  2.078877\n",
      "loss is:  2.0787227\n",
      "loss is:  2.0785694\n",
      "loss is:  2.078416\n",
      "loss is:  2.078263\n",
      "loss is:  2.0781102\n",
      "loss is:  2.0779576\n",
      "loss is:  2.0778058\n",
      "loss is:  2.0776541\n",
      "loss is:  2.0775025\n",
      "loss is:  2.0773516\n",
      "loss is:  2.0772007\n",
      "loss is:  2.0770502\n",
      "loss is:  2.0769005\n",
      "loss is:  2.0767505\n",
      "loss is:  2.0766008\n",
      "loss is:  2.0764518\n",
      "loss is:  2.0763025\n",
      "loss is:  2.0761542\n",
      "loss is:  2.076006\n",
      "loss is:  2.0758579\n",
      "loss is:  2.07571\n",
      "loss is:  2.0755627\n",
      "loss is:  2.0754158\n",
      "loss is:  2.0752692\n",
      "loss is:  2.0751226\n",
      "loss is:  2.0749762\n",
      "loss is:  2.0748305\n",
      "loss is:  2.0746849\n",
      "loss is:  2.0745397\n",
      "loss is:  2.0743947\n",
      "loss is:  2.0742502\n",
      "loss is:  2.0741055\n",
      "loss is:  2.0739617\n",
      "loss is:  2.073818\n",
      "loss is:  2.0736747\n",
      "loss is:  2.0735314\n",
      "loss is:  2.0733886\n",
      "loss is:  2.0732458\n",
      "loss is:  2.0731034\n",
      "loss is:  2.0729616\n",
      "loss is:  2.0728197\n",
      "loss is:  2.072678\n",
      "loss is:  2.072537\n",
      "loss is:  2.0723963\n",
      "loss is:  2.0722556\n",
      "loss is:  2.0721154\n",
      "loss is:  2.0719755\n",
      "loss is:  2.0718355\n",
      "loss is:  2.0716963\n",
      "loss is:  2.071557\n",
      "loss is:  2.0714183\n",
      "loss is:  2.0712795\n",
      "loss is:  2.0711408\n",
      "loss is:  2.0710032\n",
      "loss is:  2.0708654\n",
      "loss is:  2.0707278\n",
      "loss is:  2.0705907\n",
      "loss is:  2.0704536\n",
      "loss is:  2.070317\n",
      "loss is:  2.0701804\n",
      "loss is:  2.0700443\n",
      "loss is:  2.0699081\n",
      "loss is:  2.069773\n",
      "loss is:  2.0696375\n",
      "loss is:  2.0695024\n",
      "loss is:  2.0693676\n",
      "loss is:  2.0692332\n",
      "loss is:  2.069099\n",
      "loss is:  2.0689652\n",
      "loss is:  2.0688312\n",
      "loss is:  2.0686977\n",
      "loss is:  2.0685647\n",
      "loss is:  2.0684316\n",
      "loss is:  2.0682988\n",
      "loss is:  2.0681663\n",
      "loss is:  2.0680344\n",
      "loss is:  2.0679026\n",
      "loss is:  2.067771\n",
      "loss is:  2.0676394\n",
      "loss is:  2.0675082\n",
      "loss is:  2.0673773\n",
      "loss is:  2.0672467\n",
      "loss is:  2.0671163\n",
      "loss is:  2.0669863\n",
      "loss is:  2.0668564\n",
      "loss is:  2.066727\n",
      "loss is:  2.0665975\n",
      "loss is:  2.0664685\n",
      "loss is:  2.0663395\n",
      "loss is:  2.0662107\n",
      "loss is:  2.0660827\n",
      "loss is:  2.0659547\n",
      "loss is:  2.0658267\n",
      "loss is:  2.065699\n",
      "loss is:  2.0655718\n",
      "loss is:  2.0654447\n",
      "loss is:  2.0653176\n",
      "loss is:  2.065191\n",
      "loss is:  2.0650647\n",
      "loss is:  2.0649385\n",
      "loss is:  2.0648127\n",
      "loss is:  2.0646868\n",
      "loss is:  2.0645614\n",
      "loss is:  2.0644362\n",
      "loss is:  2.0643113\n",
      "loss is:  2.0641866\n",
      "loss is:  2.064062\n",
      "loss is:  2.063938\n",
      "loss is:  2.0638137\n",
      "loss is:  2.0636902\n",
      "loss is:  2.0635667\n",
      "loss is:  2.0634432\n",
      "loss is:  2.0633204\n",
      "loss is:  2.0631974\n",
      "loss is:  2.0630748\n",
      "loss is:  2.0629525\n",
      "loss is:  2.0628302\n",
      "loss is:  2.0627086\n",
      "loss is:  2.0625868\n",
      "loss is:  2.0624652\n",
      "loss is:  2.062344\n",
      "loss is:  2.062223\n",
      "loss is:  2.0621023\n",
      "loss is:  2.061982\n",
      "loss is:  2.0618615\n",
      "loss is:  2.0617414\n",
      "loss is:  2.0616214\n",
      "loss is:  2.0615017\n",
      "loss is:  2.0613825\n",
      "loss is:  2.0612633\n",
      "loss is:  2.0611444\n",
      "loss is:  2.0610254\n",
      "loss is:  2.0609071\n",
      "loss is:  2.0607886\n",
      "loss is:  2.0606706\n",
      "loss is:  2.0605528\n",
      "loss is:  2.0604353\n",
      "loss is:  2.0603178\n",
      "loss is:  2.0602005\n",
      "loss is:  2.0600834\n",
      "loss is:  2.0599666\n",
      "loss is:  2.05985\n",
      "loss is:  2.0597334\n",
      "loss is:  2.0596178\n",
      "loss is:  2.0595016\n",
      "loss is:  2.059386\n",
      "loss is:  2.0592704\n",
      "loss is:  2.0591552\n",
      "loss is:  2.05904\n",
      "loss is:  2.0589252\n",
      "loss is:  2.0588105\n",
      "loss is:  2.0586958\n",
      "loss is:  2.0585818\n",
      "loss is:  2.0584676\n",
      "loss is:  2.0583537\n",
      "loss is:  2.0582402\n",
      "loss is:  2.0581267\n",
      "loss is:  2.0580137\n",
      "loss is:  2.0579007\n",
      "loss is:  2.0577874\n",
      "loss is:  2.057675\n",
      "loss is:  2.0575624\n",
      "loss is:  2.0574505\n",
      "loss is:  2.0573387\n",
      "loss is:  2.0572267\n",
      "loss is:  2.0571153\n",
      "loss is:  2.0570035\n",
      "loss is:  2.0568926\n",
      "loss is:  2.0567815\n",
      "loss is:  2.0566707\n",
      "loss is:  2.05656\n",
      "loss is:  2.0564494\n",
      "loss is:  2.0563393\n",
      "loss is:  2.0562294\n",
      "loss is:  2.0561197\n",
      "loss is:  2.0560102\n",
      "loss is:  2.0559003\n",
      "loss is:  2.0557914\n",
      "loss is:  2.0556822\n",
      "loss is:  2.0555737\n",
      "loss is:  2.0554647\n",
      "loss is:  2.0553563\n",
      "loss is:  2.055248\n",
      "loss is:  2.0551398\n",
      "loss is:  2.055032\n",
      "loss is:  2.0549242\n",
      "loss is:  2.0548167\n",
      "loss is:  2.05471\n",
      "loss is:  2.0546024\n",
      "loss is:  2.0544956\n",
      "loss is:  2.0543885\n",
      "loss is:  2.0542822\n",
      "loss is:  2.0541759\n",
      "loss is:  2.0540695\n",
      "loss is:  2.0539634\n",
      "loss is:  2.0538576\n",
      "loss is:  2.0537522\n",
      "loss is:  2.0536468\n",
      "loss is:  2.0535414\n",
      "loss is:  2.053436\n",
      "loss is:  2.0533311\n",
      "loss is:  2.0532265\n",
      "loss is:  2.0531218\n",
      "loss is:  2.0530174\n",
      "loss is:  2.0529134\n",
      "loss is:  2.0528095\n",
      "loss is:  2.0527055\n",
      "loss is:  2.0526018\n",
      "loss is:  2.0524983\n",
      "loss is:  2.052395\n",
      "loss is:  2.052292\n",
      "loss is:  2.0521889\n",
      "loss is:  2.0520866\n",
      "loss is:  2.051984\n",
      "loss is:  2.0518813\n",
      "loss is:  2.0517793\n",
      "loss is:  2.0516772\n",
      "loss is:  2.0515752\n",
      "loss is:  2.0514736\n",
      "loss is:  2.0513718\n",
      "loss is:  2.0512707\n",
      "loss is:  2.0511696\n",
      "loss is:  2.0510683\n",
      "loss is:  2.0509675\n",
      "loss is:  2.0508668\n",
      "loss is:  2.0507662\n",
      "loss is:  2.050666\n",
      "loss is:  2.0505657\n",
      "loss is:  2.0504658\n",
      "loss is:  2.0503662\n",
      "loss is:  2.0502663\n",
      "loss is:  2.050167\n",
      "loss is:  2.0500674\n",
      "loss is:  2.0499685\n",
      "loss is:  2.0498693\n",
      "loss is:  2.0497706\n",
      "loss is:  2.0496721\n",
      "loss is:  2.0495734\n",
      "loss is:  2.049475\n",
      "loss is:  2.0493772\n",
      "loss is:  2.0492792\n",
      "loss is:  2.049181\n",
      "loss is:  2.0490835\n",
      "loss is:  2.0489862\n",
      "loss is:  2.0488887\n",
      "loss is:  2.0487916\n",
      "loss is:  2.0486946\n",
      "loss is:  2.0485976\n",
      "loss is:  2.0485008\n",
      "loss is:  2.0484045\n",
      "loss is:  2.048308\n",
      "loss is:  2.0482116\n",
      "loss is:  2.0481157\n",
      "loss is:  2.04802\n",
      "loss is:  2.047924\n",
      "loss is:  2.0478284\n",
      "loss is:  2.047733\n",
      "loss is:  2.0476377\n",
      "loss is:  2.0475428\n",
      "loss is:  2.0474477\n",
      "loss is:  2.0473528\n",
      "loss is:  2.0472584\n",
      "loss is:  2.0471637\n",
      "loss is:  2.0470695\n",
      "loss is:  2.0469751\n",
      "loss is:  2.046881\n",
      "loss is:  2.046787\n",
      "loss is:  2.0466933\n",
      "loss is:  2.0465999\n",
      "loss is:  2.0465066\n",
      "loss is:  2.046413\n",
      "loss is:  2.04632\n",
      "loss is:  2.0462272\n",
      "loss is:  2.0461345\n",
      "loss is:  2.0460415\n",
      "loss is:  2.0459492\n",
      "loss is:  2.0458567\n",
      "loss is:  2.0457644\n",
      "loss is:  2.0456722\n",
      "loss is:  2.0455804\n",
      "loss is:  2.0454888\n",
      "loss is:  2.045397\n",
      "loss is:  2.0453057\n",
      "loss is:  2.0452142\n",
      "loss is:  2.0451229\n",
      "loss is:  2.045032\n",
      "loss is:  2.0449412\n",
      "loss is:  2.0448503\n",
      "loss is:  2.0447598\n",
      "loss is:  2.0446694\n",
      "loss is:  2.0445788\n",
      "loss is:  2.0444887\n",
      "loss is:  2.0443985\n",
      "loss is:  2.0443087\n",
      "loss is:  2.044219\n",
      "loss is:  2.0441296\n",
      "loss is:  2.04404\n",
      "loss is:  2.0439508\n",
      "loss is:  2.0438614\n",
      "loss is:  2.0437727\n",
      "loss is:  2.0436835\n",
      "loss is:  2.0435948\n",
      "loss is:  2.0435061\n",
      "loss is:  2.0434177\n",
      "loss is:  2.043329\n",
      "loss is:  2.043241\n",
      "loss is:  2.043153\n",
      "loss is:  2.0430653\n",
      "loss is:  2.0429769\n",
      "loss is:  2.0428898\n",
      "loss is:  2.042802\n",
      "loss is:  2.0427146\n",
      "loss is:  2.0426276\n",
      "loss is:  2.0425403\n",
      "loss is:  2.0424535\n",
      "loss is:  2.0423665\n",
      "loss is:  2.0422797\n",
      "loss is:  2.0421934\n",
      "loss is:  2.042107\n",
      "loss is:  2.0420206\n",
      "loss is:  2.0419347\n",
      "loss is:  2.0418484\n",
      "loss is:  2.0417626\n",
      "loss is:  2.0416768\n",
      "loss is:  2.0415912\n",
      "loss is:  2.0415056\n",
      "loss is:  2.0414202\n",
      "loss is:  2.041335\n",
      "loss is:  2.04125\n",
      "loss is:  2.0411649\n",
      "loss is:  2.0410802\n",
      "loss is:  2.0409956\n",
      "loss is:  2.0409107\n",
      "loss is:  2.0408266\n",
      "loss is:  2.0407422\n",
      "loss is:  2.0406578\n",
      "loss is:  2.0405736\n",
      "loss is:  2.0404897\n",
      "loss is:  2.0404062\n",
      "loss is:  2.0403223\n",
      "loss is:  2.0402389\n",
      "loss is:  2.0401554\n",
      "loss is:  2.0400722\n",
      "loss is:  2.039989\n",
      "loss is:  2.0399058\n",
      "loss is:  2.039823\n",
      "loss is:  2.03974\n",
      "loss is:  2.0396576\n",
      "loss is:  2.0395749\n",
      "loss is:  2.0394926\n",
      "loss is:  2.03941\n",
      "loss is:  2.039328\n",
      "loss is:  2.0392458\n",
      "loss is:  2.0391643\n",
      "loss is:  2.0390823\n",
      "loss is:  2.0390003\n",
      "loss is:  2.038919\n",
      "loss is:  2.0388374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is:  2.0387561\n",
      "loss is:  2.0386748\n",
      "loss is:  2.038594\n",
      "loss is:  2.0385132\n",
      "loss is:  2.0384321\n",
      "loss is:  2.0383515\n",
      "loss is:  2.0382707\n",
      "loss is:  2.0381904\n",
      "loss is:  2.03811\n",
      "loss is:  2.0380297\n",
      "loss is:  2.0379493\n",
      "loss is:  2.0378697\n",
      "loss is:  2.0377896\n",
      "loss is:  2.03771\n",
      "loss is:  2.0376303\n",
      "loss is:  2.037551\n",
      "loss is:  2.0374715\n",
      "loss is:  2.0373921\n",
      "loss is:  2.037313\n",
      "loss is:  2.0372338\n",
      "loss is:  2.037155\n",
      "loss is:  2.037076\n",
      "loss is:  2.0369976\n",
      "loss is:  2.0369186\n",
      "loss is:  2.0368404\n",
      "loss is:  2.036762\n",
      "loss is:  2.0366836\n",
      "loss is:  2.0366056\n",
      "loss is:  2.0365279\n",
      "loss is:  2.0364494\n",
      "loss is:  2.0363715\n",
      "loss is:  2.036294\n",
      "loss is:  2.0362165\n",
      "loss is:  2.0361392\n",
      "loss is:  2.0360615\n",
      "loss is:  2.0359845\n",
      "loss is:  2.0359075\n",
      "loss is:  2.0358303\n",
      "loss is:  2.0357537\n",
      "loss is:  2.0356765\n",
      "loss is:  2.0356\n",
      "loss is:  2.0355234\n",
      "loss is:  2.0354471\n",
      "loss is:  2.0353706\n",
      "loss is:  2.0352943\n",
      "loss is:  2.0352182\n",
      "loss is:  2.0351424\n",
      "loss is:  2.0350661\n",
      "loss is:  2.0349905\n",
      "loss is:  2.034915\n",
      "loss is:  2.0348392\n",
      "loss is:  2.0347636\n",
      "loss is:  2.0346882\n",
      "loss is:  2.0346131\n",
      "loss is:  2.034538\n",
      "loss is:  2.0344627\n",
      "loss is:  2.034388\n",
      "loss is:  2.034313\n",
      "loss is:  2.0342383\n",
      "loss is:  2.0341637\n",
      "loss is:  2.0340893\n",
      "loss is:  2.034015\n",
      "loss is:  2.0339406\n",
      "loss is:  2.0338664\n",
      "loss is:  2.0337923\n",
      "loss is:  2.0337183\n",
      "loss is:  2.0336444\n",
      "loss is:  2.0335705\n",
      "loss is:  2.033497\n",
      "loss is:  2.0334232\n",
      "loss is:  2.0333498\n",
      "loss is:  2.0332763\n",
      "loss is:  2.0332031\n",
      "loss is:  2.03313\n",
      "loss is:  2.0330567\n",
      "loss is:  2.0329838\n",
      "loss is:  2.032911\n",
      "loss is:  2.0328383\n",
      "loss is:  2.0327656\n",
      "loss is:  2.0326931\n",
      "loss is:  2.0326207\n",
      "loss is:  2.0325484\n",
      "loss is:  2.0324762\n",
      "loss is:  2.032404\n",
      "loss is:  2.032332\n",
      "loss is:  2.03226\n",
      "loss is:  2.032188\n",
      "loss is:  2.0321164\n",
      "loss is:  2.0320446\n",
      "loss is:  2.031973\n",
      "loss is:  2.0319016\n",
      "loss is:  2.0318305\n",
      "loss is:  2.031759\n",
      "loss is:  2.0316877\n",
      "loss is:  2.0316172\n",
      "loss is:  2.0315459\n",
      "loss is:  2.0314748\n",
      "loss is:  2.031404\n",
      "loss is:  2.0313334\n",
      "loss is:  2.0312629\n",
      "loss is:  2.0311925\n",
      "loss is:  2.031122\n",
      "loss is:  2.0310516\n",
      "loss is:  2.0309818\n",
      "loss is:  2.0309114\n",
      "loss is:  2.0308414\n",
      "loss is:  2.0307715\n",
      "loss is:  2.0307019\n",
      "loss is:  2.0306323\n",
      "loss is:  2.0305626\n",
      "loss is:  2.030493\n",
      "loss is:  2.0304234\n",
      "loss is:  2.0303543\n",
      "loss is:  2.0302846\n",
      "loss is:  2.030216\n",
      "loss is:  2.0301468\n",
      "loss is:  2.0300777\n",
      "loss is:  2.0300088\n",
      "loss is:  2.0299401\n",
      "loss is:  2.0298715\n",
      "loss is:  2.0298028\n",
      "loss is:  2.0297344\n",
      "loss is:  2.0296662\n",
      "loss is:  2.0295975\n",
      "loss is:  2.0295293\n",
      "loss is:  2.0294611\n",
      "loss is:  2.0293932\n",
      "loss is:  2.029325\n",
      "loss is:  2.0292575\n",
      "loss is:  2.0291893\n",
      "loss is:  2.0291219\n",
      "loss is:  2.029054\n",
      "loss is:  2.0289867\n",
      "loss is:  2.0289192\n",
      "loss is:  2.028852\n",
      "loss is:  2.0287848\n",
      "loss is:  2.0287178\n",
      "loss is:  2.0286505\n",
      "loss is:  2.0285835\n",
      "loss is:  2.0285168\n",
      "loss is:  2.0284498\n",
      "loss is:  2.028383\n",
      "loss is:  2.0283165\n",
      "loss is:  2.02825\n",
      "loss is:  2.0281835\n",
      "loss is:  2.0281172\n",
      "loss is:  2.028051\n",
      "loss is:  2.0279849\n",
      "loss is:  2.0279183\n",
      "loss is:  2.0278525\n",
      "loss is:  2.027787\n",
      "loss is:  2.027721\n",
      "loss is:  2.027655\n",
      "loss is:  2.027589\n",
      "loss is:  2.0275238\n",
      "loss is:  2.0274582\n"
     ]
    }
   ],
   "source": [
    "n_iters = 2000\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
    "    print('loss is: ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train} ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.264247   -0.41725922 -1.4768288  -0.37130958  0.45540696]\n",
      " [ 1.520511   -1.0673778  -0.77568173  0.28071332  0.7481448 ]\n",
      " [ 1.3156799  -1.2172872   0.08095276  0.11522432  1.0912459 ]\n",
      " [ 0.78956795 -1.4058923   0.10220371  0.99333316  0.34635052]\n",
      " [ 0.26297823 -2.2856889   0.3196364   1.3284935  -0.19323258]\n",
      " [-0.5427734  -1.5875663   0.24913833  3.48033    -1.2983516 ]\n",
      " [-1.0829904  -0.4992789   1.0056132   1.5489657   0.22153309]\n",
      " [-1.7959106  -0.03273933  0.8328702   2.336976   -0.44873044]\n",
      " [-0.7728766   0.02592054 -0.06531389  2.2033794   0.6716655 ]\n",
      " [-0.5338104   0.4372206  -0.54687166  2.374825    0.05574702]\n",
      " [-0.69851404  1.2253596  -0.7222803   1.3455998  -0.08960064]\n",
      " [-0.31501937  1.658966   -1.1831833   1.2943054  -0.18317729]\n",
      " [ 0.0112107   2.0311317  -2.2743087  -0.29924643 -0.2685427 ]\n",
      " [-1.7275635   0.46908617 -1.8699778   0.16464368 -1.5075141 ]\n",
      " [-1.0391134   0.85410744 -1.2025309  -1.0926648   0.1172104 ]\n",
      " [-1.049586    0.80048573 -0.46096337 -1.2719802   0.5521828 ]\n",
      " [-1.0123801  -0.40133262 -1.3019748  -1.2345412  -1.0669838 ]\n",
      " [ 0.12640658  0.05517794  0.39139822 -1.2322984   0.34791455]\n",
      " [ 0.49724683  0.24232672  0.66936105 -1.6651882   0.25655714]\n",
      " [ 0.6177649   0.5765614   0.84011394 -1.0524336  -0.06069468]\n",
      " [ 0.49226746 -1.2639297  -0.333386   -0.7429841  -1.6786495 ]\n",
      " [ 0.77459574  0.605872    0.04949544  0.1736368  -1.4470974 ]\n",
      " [ 0.46950403 -1.939209   -0.9277934  -2.5623338   0.3304504 ]\n",
      " [ 0.974069   -1.1216625  -3.112394    0.70268613  0.63310957]\n",
      " [ 2.3880546  -0.48282072  0.07445761  0.2124964   1.1263564 ]\n",
      " [ 0.3881837   0.14839855 -0.04448485 -0.8862217  -1.2058395 ]\n",
      " [-1.2534132   0.70725465  0.93435293 -0.46176812 -0.55010533]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.3827703  -0.4582397  -0.99734366 -0.948996   -0.00789574]\n",
      " [ 1.6390344  -1.1083583  -0.29619655 -0.2969731   0.2848421 ]\n",
      " [ 1.4342033  -1.2582676   0.5604379  -0.4624621   0.62794316]\n",
      " [ 0.90809125 -1.4468727   0.5816889   0.41564673 -0.11695218]\n",
      " [ 0.38150156 -2.3266695   0.7991216   0.75080705 -0.65653527]\n",
      " [-0.42425013 -1.6285467   0.7286235   2.9026437  -1.7616544 ]\n",
      " [-0.9644671  -0.54025936  1.4850984   0.97127926 -0.24176961]\n",
      " [-1.6773872  -0.07371981  1.3123554   1.7592896  -0.91203314]\n",
      " [-0.6543533  -0.01505995  0.41417128  1.625693    0.20836279]\n",
      " [-0.41528708  0.39624012 -0.06738648  1.7971386  -0.40755567]\n",
      " [-0.57999074  1.1843791  -0.24279514  0.76791334 -0.55290335]\n",
      " [-0.19649605  1.6179855  -0.70369816  0.716619   -0.64647996]\n",
      " [ 0.12973401  1.9901513  -1.7948235  -0.87693286 -0.7318454 ]\n",
      " [-1.6090401   0.42810568 -1.3904927  -0.41304275 -1.9708169 ]\n",
      " [-0.9205901   0.8131269  -0.7230457  -1.6703513  -0.3460923 ]\n",
      " [-0.93106276  0.7595053   0.01852182 -1.8496666   0.08888009]\n",
      " [-0.8938568  -0.4423131  -0.8224896  -1.8122276  -1.5302866 ]\n",
      " [ 0.2449299   0.01419745  0.8708834  -1.8099848  -0.11538815]\n",
      " [ 0.61577016  0.20134623  1.1488463  -2.2428746  -0.20674556]\n",
      " [ 0.7362882   0.5355809   1.3195992  -1.63012    -0.52399737]\n",
      " [ 0.6107908  -1.3049102   0.14609918 -1.3206706  -2.1419523 ]\n",
      " [ 0.89311904  0.56489146  0.5289806  -0.40404963 -1.9104002 ]\n",
      " [ 0.58802736 -1.9801894  -0.4483082  -3.1400204  -0.13285232]\n",
      " [ 1.0925924  -1.162643   -2.6329088   0.1249997   0.16980687]\n",
      " [ 2.506578   -0.5238012   0.5539428  -0.36519003  0.66305363]\n",
      " [ 0.506707    0.10741806  0.43500033 -1.4639082  -1.6691422 ]\n",
      " [-1.1348898   0.6662742   1.4138381  -1.0394546  -1.0134081 ]]\n"
     ]
    }
   ],
   "source": [
    "vectors = sess.run(w1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9644671  -0.54025936  1.4850984   0.97127926 -0.24176961]\n"
     ]
    }
   ],
   "source": [
    "print( vectors[ word2int['बिहीबार'] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum( (vec1-vec2)**2 ) )\n",
    "\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # lo act like pos infinity\n",
    "    min_index  = -1\n",
    "    \n",
    "    query_vector = vectors[word_index]\n",
    "    \n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "            \n",
    "    return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "जिल्ला\n"
     ]
    }
   ],
   "source": [
    "print(int2word[find_closest(word2int['बिहीबार'], vectors)])\n",
    "# print(int2word[find_closest(word2int['queen'], vectors)])\n",
    "# print(int2word[find_closest(word2int['royal'], vectors)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
